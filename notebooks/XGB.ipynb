{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UywYg7bSPxMi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    Binarizer,\n",
    "    StandardScaler,\n",
    "    LabelBinarizer,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearnex import patch_sklearn\n",
    "\n",
    "# patch_sklearn()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# from xgboost import XGBRFClassifier, XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# import dtale\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# sns.set()\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.plotting.backend = \"matplotlib\"\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    MinMaxScaler,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "import warnings\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    # StratifiedGroupKFold,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "\n",
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    CategoricalNB,\n",
    "    MultinomialNB,\n",
    "    ComplementNB,\n",
    "    GaussianNB,\n",
    ")\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "nb_est = [CategoricalNB(), MultinomialNB(), ComplementNB(), GaussianNB()]\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from joblib import parallel_backend\n",
    "from autosklearn.automl import AutoMLClassifier\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wZc_Y9u_QC0u"
   },
   "outputs": [],
   "source": [
    "dtype_info = {\n",
    "    \"v_1\": \"Binary\",\n",
    "    \"v_26\": \"Binary\",\n",
    "    \"v_11\": \"Binary\",\n",
    "    \"v_14\": \"Binary\",\n",
    "    \"v_30\": \"Binary\",\n",
    "    \"v_28\": \"Binary\",\n",
    "    \"v_9\": \"Binary\",\n",
    "    \"v_27\": \"Binary\",\n",
    "    \"v_32\": \"Nominal\",\n",
    "    \"v_4\": \"Nominal\",\n",
    "    \"v_3\": \"Nominal\",\n",
    "    \"v_20\": \"Nominal\",\n",
    "    \"v_21\": \"Nominal\",\n",
    "    \"v_18\": \"Nominal\",\n",
    "    \"v_25\": \"Nominal\",\n",
    "    \"v_12\": \"Nominal\",\n",
    "    \"v_31\": \"Ordinal\",\n",
    "    \"v_15\": \"Ordinal\",\n",
    "    \"v_19\": \"Ordinal\",\n",
    "    \"v_13\": \"Ordinal\",\n",
    "    \"v_33\": \"Ordinal\",\n",
    "    \"v_17\": \"Ordinal\",\n",
    "    \"v_29\": \"Ordinal\",\n",
    "    \"v_23\": \"Ordinal\",\n",
    "    \"v_6\": \"Ordinal\",\n",
    "    \"v_24\": \"Ordinal\",\n",
    "    \"v_10\": \"Ordinal\",\n",
    "    \"v_5\": \"Ordinal\",\n",
    "    \"v_22\": \"Ordinal\",\n",
    "    \"v_0\": \"Ordinal\",\n",
    "    \"v_16\": \"Ratio\",\n",
    "    \"v_2\": \"Ratio\",\n",
    "    \"v_8\": \"Ratio\",\n",
    "    \"v_7\": \"Ratio\",\n",
    "    \"v_39\": \"Ratio\",\n",
    "    \"v_37\": \"Ratio\",\n",
    "    \"v_38\": \"Ratio\",\n",
    "    \"v_34\": \"Ratio\",\n",
    "    \"v_40\": \"Ratio\",\n",
    "    \"v_36\": \"Ratio\",\n",
    "    \"v_35\": \"Ratio\",\n",
    "}\n",
    "data = pd.read_csv(\n",
    "    \"../data/train.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "ordinal = [i for i in dtype_info if dtype_info[i] == \"Ordinal\"]\n",
    "nominal = [i for i in dtype_info if dtype_info[i] == \"Nominal\"]\n",
    "binary = [i for i in dtype_info if dtype_info[i] == \"Binary\"]\n",
    "ratio = [i for i in dtype_info if dtype_info[i] == \"Ratio\"]\n",
    "\n",
    "\n",
    "def categorise_data(data):\n",
    "    ordinal_data = data.loc[:, ordinal]\n",
    "    nominal_data = data.loc[:, nominal]\n",
    "    binary_data = data.loc[:, binary]\n",
    "    ratio_data = data.loc[:, ratio]\n",
    "    return ordinal_data, nominal_data, binary_data, ratio_data\n",
    "\n",
    "\n",
    "ordinal_data, nominal_data, binary_data, ratio_data = categorise_data(data)\n",
    "\n",
    "\n",
    "def gen_train_test(data, p):\n",
    "    Y = data.label\n",
    "    X_2 = Y_2 = Y[Y == 2].index\n",
    "    X_0 = Y_0 = Y[Y == 0].index\n",
    "    X_1 = Y_1 = Y[Y == 1].index\n",
    "    train_size = int(p * Y_2.shape[0])\n",
    "    test_size = int((1 - p) * Y_2.shape[0])\n",
    "\n",
    "    train_idx_2 = np.random.choice(Y_2, (train_size,))\n",
    "    train_idx_1 = np.random.choice(Y_1, (train_size,))\n",
    "    train_idx_0 = np.random.choice(Y_0, (train_size,))\n",
    "    train_idx = np.r_[train_idx_0, train_idx_1, train_idx_2]\n",
    "    # train_idx.shape\n",
    "\n",
    "    test_idx_2 = np.random.choice(np.setdiff1d(Y_2, train_idx_2), (test_size,))\n",
    "    test_idx_1 = np.random.choice(np.setdiff1d(Y_1, train_idx_1), (test_size,))\n",
    "    test_idx_0 = np.random.choice(np.setdiff1d(Y_0, train_idx_0), (test_size,))\n",
    "    test_idx = np.r_[test_idx_0, test_idx_1, test_idx_2]\n",
    "    # test_idx.shape\n",
    "    return train_idx, test_idx\n",
    "\n",
    "\n",
    "data__ = pd.read_parquet(\"../data/data_with_ridit.hdfs\", engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezYX9VnORxuF",
    "outputId": "d0e2a8d4-3123-49f4-cb24-caa4a4603d1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "HcLJzpF3Rob7",
    "outputId": "a66e947d-9e1d-4f5f-ef92-f97bf0095690"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6274"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "n_runs = 100\n",
    "r_max = -100\n",
    "r_max_data = None\n",
    "for _ in tqdm(range(100)):\n",
    "\n",
    "    train_idx, test_idx = gen_train_test(data, 0.8)\n",
    "    X_train, y_train = (\n",
    "        ordinal_data.loc[train_idx, :].astype(\"int\"),\n",
    "        data[\"label\"].loc[train_idx],\n",
    "    )\n",
    "    X_test, y_test = (\n",
    "        ordinal_data.loc[test_idx, :].astype(\"int\"),\n",
    "        data[\"label\"].loc[test_idx],\n",
    "    )\n",
    "\n",
    "    dtc = RandomForestClassifier(\n",
    "        n_jobs=-1, random_state=42, criterion=\"entropy\", min_samples_leaf=4\n",
    "    )\n",
    "    wf = make_pipeline(dtc)\n",
    "    with parallel_backend(\"threading\", n_jobs=10):\n",
    "        wf.fit(X_train, y_train)\n",
    "        wf.score(X_test, y_test)\n",
    "        r = sklearn.metrics.f1_score(wf.predict(X_test), y_test, average=\"macro\")\n",
    "        if r > r_max:\n",
    "            r_max = r\n",
    "            r_max_data = (train_idx, test_idx)\n",
    "        results.append(r)\n",
    "results.sort()\n",
    "# plt.hist(results)\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2trHTcNKSzcg"
   },
   "outputs": [],
   "source": [
    "train_idx, test_idx = r_max_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "vPgZcZN7W7w4",
    "outputId": "c515f65e-c31f-44de-8ae6-3c5f5f52aa00"
   },
   "outputs": [],
   "source": [
    "from autosklearn.automl import AutoMLClassifier\n",
    "from distributed import Client\n",
    "\n",
    "client = Client(processes=False)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLClassifier(\n",
    "    time_left_for_this_task=60, dask_client=client, per_run_time_limit=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_ = [x for x in data__.columns if \"__oum\" in x or \"__ridit\" in x or \"__logit\" in x]\n",
    "logit_data = pd.concat(\n",
    "    [(ordinal_data * 1000).astype(\"category\"), data__.loc[:, logit_]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = ordinal_data.loc[train_idx, :], data[\"label\"].loc[train_idx]\n",
    "X_test, y_test = ordinal_data.loc[test_idx, :], data[\"label\"].loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with parallel_backend('loky'):\n",
    "automl.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    dataset_name=\"ordinal_data with logit,ridit, ordinal uniform variable\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.show_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ordina"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPysBQa8OrfAE4su7j0p8lV",
   "include_colab_link": true,
   "name": "XGB.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
