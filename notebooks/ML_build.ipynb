{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90f0379-dcfe-4789-98e1-095a9661cea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    Binarizer,\n",
    "    StandardScaler,\n",
    "    LabelBinarizer,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "# from xgboost import XGBRFClassifier, XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "# sns.set()\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    Product,\n",
    "    RBF,\n",
    "    CompoundKernel,\n",
    "    Exponentiation,\n",
    "    Matern,\n",
    "    Sum,\n",
    ")\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from category_encoders import (\n",
    "    TargetEncoder,\n",
    "    BackwardDifferenceEncoder,\n",
    "    BaseNEncoder,\n",
    "    BinaryEncoder,\n",
    "    CatBoostEncoder,\n",
    "    CatBoostEncoder,\n",
    "    GLMMEncoder,\n",
    "    HelmertEncoder,\n",
    "    JamesSteinEncoder,\n",
    "    PolynomialEncoder,\n",
    "    QuantileEncoder,\n",
    "    SumEncoder,\n",
    "    SummaryEncoder,\n",
    "    WOEEncoder,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    MinMaxScaler,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "import warnings\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import plotly.express as px\n",
    "# from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    # StratifiedGroupKFold,\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    HalvingGridSearchCV,\n",
    "    HalvingRandomSearchCV\n",
    ")\n",
    "import sigopt\n",
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    CategoricalNB,\n",
    "    MultinomialNB,\n",
    "    ComplementNB,\n",
    "    GaussianNB,\n",
    ")\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# nb_est = [CategoricalNB(), MultinomialNB(), ComplementNB(), GaussianNB()]\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_selection import (\n",
    "    mutual_info_classif,\n",
    "    SelectKBest,\n",
    "    f_classif,\n",
    "    chi2,\n",
    "    RFE,\n",
    "    SelectFdr,\n",
    "    SelectFpr,\n",
    "    SelectFwe,\n",
    "    SelectPercentile,\n",
    ")\n",
    "from tbb import Monkey\n",
    "# from xgboost import XGBClassifier\n",
    "import os\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from joblib import parallel_backend\n",
    "from category_encoders.wrapper import PolynomialWrapper, NestedCVWrapper\n",
    "# from autosklearn.automl import AutoMLClassifier\n",
    "import sklearn.metrics\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pd.options.display.max_columns = 50\n",
    "set_config(display=\"diagram\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dtype_info = {\n",
    "    \"v_1\": \"Binary\",\n",
    "    \"v_26\": \"Binary\",\n",
    "    \"v_11\": \"Binary\",\n",
    "    \"v_14\": \"Binary\",\n",
    "    \"v_30\": \"Binary\",\n",
    "    \"v_28\": \"Binary\",\n",
    "    \"v_9\": \"Binary\",\n",
    "    \"v_27\": \"Binary\",\n",
    "    \"v_32\": \"Nominal\",\n",
    "    \"v_4\": \"Nominal\",\n",
    "    \"v_3\": \"Nominal\",\n",
    "    \"v_20\": \"Nominal\",\n",
    "    \"v_21\": \"Nominal\",\n",
    "    \"v_18\": \"Nominal\",\n",
    "    \"v_25\": \"Nominal\",\n",
    "    \"v_12\": \"Nominal\",\n",
    "    \"v_31\": \"Ordinal\",\n",
    "    \"v_15\": \"Ordinal\",\n",
    "    \"v_19\": \"Ordinal\",\n",
    "    \"v_13\": \"Ordinal\",\n",
    "    \"v_33\": \"Ordinal\",\n",
    "    \"v_17\": \"Ordinal\",\n",
    "    \"v_29\": \"Ordinal\",\n",
    "    \"v_23\": \"Ordinal\",\n",
    "    \"v_6\": \"Ordinal\",\n",
    "    \"v_24\": \"Ordinal\",\n",
    "    \"v_10\": \"Ordinal\",\n",
    "    \"v_5\": \"Ordinal\",\n",
    "    \"v_22\": \"Ordinal\",\n",
    "    \"v_0\": \"Ordinal\",\n",
    "    \"v_16\": \"Ratio\",\n",
    "    \"v_2\": \"Ratio\",\n",
    "    \"v_8\": \"Ratio\",\n",
    "    \"v_7\": \"Ratio\",\n",
    "    \"v_39\": \"Ratio\",\n",
    "    \"v_37\": \"Ratio\",\n",
    "    \"v_38\": \"Ratio\",\n",
    "    \"v_34\": \"Ratio\",\n",
    "    \"v_40\": \"Ratio\",\n",
    "    \"v_36\": \"Ratio\",\n",
    "    \"v_35\": \"Ratio\",\n",
    "}\n",
    "# data = pd.read_csv(\n",
    "#     \"../data/train.csv\",\n",
    "#     index_col=0,\n",
    "# )\n",
    "data__ = pd.read_parquet(\"../data/data_with_ridit.hdfs\", engine=\"fastparquet\")\n",
    "prediction_data = pd.read_parquet(\"../data/test.parquet\", engine=\"fastparquet\")\n",
    "data = pd.read_parquet(\"../data/train.parquet\", engine=\"fastparquet\")\n",
    "ordinal = [i for i in dtype_info if dtype_info[i] == \"Ordinal\"]\n",
    "nominal = [i for i in dtype_info if dtype_info[i] == \"Nominal\"]\n",
    "binary = [i for i in dtype_info if dtype_info[i] == \"Binary\"]\n",
    "ratio = [i for i in dtype_info if dtype_info[i] == \"Ratio\"]\n",
    "final_data = pd.read_parquet(\"../data/final_data.parquet\", engine=\"fastparquet\")\n",
    "final_pred_data = pd.read_parquet(\n",
    "    \"../data/final_pred_data.parquet\", engine=\"fastparquet\"\n",
    ")\n",
    "baseline_prediction_data = pd.read_parquet('../data/baseline.parquet')\n",
    "\n",
    "\n",
    "def categorise_data(data):\n",
    "    ordinal_data = data.loc[:, ordinal]\n",
    "    nominal_data = data.loc[:, nominal]\n",
    "    binary_data = data.loc[:, binary]\n",
    "    ratio_data = data.loc[:, ratio]\n",
    "    return ordinal_data, nominal_data, binary_data, ratio_data\n",
    "\n",
    "\n",
    "ordinal_data, nominal_data, binary_data, ratio_data = categorise_data(final_data)\n",
    "baseline_prediction_data.rename(columns={'label':'target'}, inplace=True)\n",
    "final_data.rename(columns={'label':'target'}, inplace=True)\n",
    "data.rename(columns={'label':'target'}, inplace=True)\n",
    "# baseline_prediction_data\n",
    "\n",
    "bs = pd.concat([final_data,baseline_prediction_data], axis=0,ignore_index=True)\n",
    "nominal_master_db = bs.loc[:, nominal]\n",
    "\n",
    "def gen_train_test(data, p):\n",
    "    Y = data.target\n",
    "    X_2 = Y_2 = Y[Y == 2].index\n",
    "    X_0 = Y_0 = Y[Y == 0].index\n",
    "    X_1 = Y_1 = Y[Y == 1].index\n",
    "    train_size = int(p * Y_2.shape[0])\n",
    "    test_size = int((1 - p) * Y_2.shape[0])\n",
    "\n",
    "    train_idx_2 = np.random.choice(Y_2, (train_size,))\n",
    "    train_idx_1 = np.random.choice(Y_1, (train_size,))\n",
    "    train_idx_0 = np.random.choice(Y_0, (train_size,))\n",
    "    train_idx = np.r_[train_idx_0, train_idx_1, train_idx_2]\n",
    "    # train_idx.shape\n",
    "\n",
    "    test_idx_2 = np.random.choice(np.setdiff1d(Y_2, train_idx_2), (test_size,))\n",
    "    test_idx_1 = np.random.choice(np.setdiff1d(Y_1, train_idx_1), (test_size,))\n",
    "    test_idx_0 = np.random.choice(np.setdiff1d(Y_0, train_idx_0), (test_size,))\n",
    "    test_idx = np.r_[test_idx_0, test_idx_1, test_idx_2]\n",
    "    # test_idx.shape\n",
    "    return train_idx, test_idx\n",
    "\n",
    "nominal_cont_map=defaultdict(dict)\n",
    "nominal_indvl_map=defaultdict(dict)\n",
    "for c in nominal:\n",
    "    un = sorted(nominal_master_db[c].unique().tolist())\n",
    "    n = len(un)\n",
    "    new_id = list(range(n))\n",
    "    nominal_indvl_map[c] = dict(zip(un,new_id))\n",
    "start = 0\n",
    "for c in nominal:\n",
    "    un = sorted(nominal_master_db[c].unique().tolist())\n",
    "    n = len(un)\n",
    "    new_id = list(range(start,start+n))\n",
    "    nominal_cont_map[c] = dict(zip(un,new_id))\n",
    "    start += n\n",
    "\n",
    "\n",
    "nominal_master_db_indvl = nominal_master_db.copy()\n",
    "nominal_master_db_cont = nominal_master_db.copy()\n",
    "\n",
    "\n",
    "# nominal_indvl_map\n",
    "def nm_indvl_data_trnsform(row):\n",
    "    for c in nominal:\n",
    "        curr = row[c]\n",
    "        row[c] = nominal_indvl_map[c][curr]\n",
    "    return row\n",
    "\n",
    "\n",
    "test1_nominal = nominal_master_db_indvl.apply(nm_indvl_data_trnsform,axis=1)\n",
    "\n",
    "\n",
    "def nm_cont_data_trnsform(row):\n",
    "    for c in nominal:\n",
    "        curr = row[c]\n",
    "        row[c] = nominal_cont_map[c][curr]\n",
    "    return row\n",
    "\n",
    "\n",
    "test2_nominal = nominal_master_db_cont.apply(nm_cont_data_trnsform,axis=1)\n",
    "\n",
    "\n",
    "def best_n_features(n, X_train, y_train):\n",
    "    ohe = OneHotEncoder(\n",
    "        min_frequency=0.00001, handle_unknown=\"infrequent_if_exist\", sparse=False\n",
    "    )\n",
    "    X_train_t = ohe.fit_transform(X_train)\n",
    "    mic = mutual_info_classif(X_train_t, y_train, discrete_features=True)\n",
    "\n",
    "    return ohe.get_feature_names_out()[mic.argsort()[-n:]]\n",
    "\n",
    "\n",
    "# prediction_data = pd.read_pickle(\"../data/pred_data.pkl\")\n",
    "# est_ = [(\"cnb\",CategoricalNB()),]\n",
    "def iv_woe(data, target, bins=10, show_woe=False):\n",
    "\n",
    "    # Empty Dataframe\n",
    "    newDF, woeDF = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Extract Column Names\n",
    "    cols = data.columns\n",
    "\n",
    "    # Run WOE and IV on all the independent variables\n",
    "    for ivars in cols[~cols.isin([target])]:\n",
    "        if (data[ivars].dtype.kind in \"bifc\") and (len(np.unique(data[ivars])) > 1000):\n",
    "            binned_x = pd.qcut(data[ivars], bins, duplicates=\"drop\")\n",
    "            d0 = pd.DataFrame({\"x\": binned_x, \"y\": data[target]})\n",
    "        else:\n",
    "            d0 = pd.DataFrame({\"x\": data[ivars], \"y\": data[target]})\n",
    "        d0 = d0.astype({\"x\": str})\n",
    "        d = d0.groupby(\"x\", as_index=False, dropna=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "        d.columns = [\"Cutoff\", \"N\", \"Events\"]\n",
    "        d[\"% of Events\"] = np.maximum(d[\"Events\"], 0.5) / d[\"Events\"].sum()\n",
    "        d[\"Non-Events\"] = d[\"N\"] - d[\"Events\"]\n",
    "        d[\"% of Non-Events\"] = np.maximum(d[\"Non-Events\"], 0.5) / d[\"Non-Events\"].sum()\n",
    "        d[\"WoE\"] = np.log(d[\"% of Non-Events\"] / d[\"% of Events\"])\n",
    "        d[\"IV\"] = d[\"WoE\"] * (d[\"% of Non-Events\"] - d[\"% of Events\"])\n",
    "        d.insert(loc=0, column=\"Variable\", value=ivars)\n",
    "        print(\"Information value of \" + ivars + \" is \" + str(round(d[\"IV\"].sum(), 6)))\n",
    "        temp = pd.DataFrame(\n",
    "            {\"Variable\": [ivars], \"IV\": [d[\"IV\"].sum()]}, columns=[\"Variable\", \"IV\"]\n",
    "        )\n",
    "        newDF = pd.concat([newDF, temp], axis=0)\n",
    "        woeDF = pd.concat([woeDF, d], axis=0)\n",
    "\n",
    "        # Show WOE Table\n",
    "        if show_woe == True:\n",
    "            print(d)\n",
    "    return newDF, woeDF\n",
    "\n",
    "def wf_create(cat_encoder, model):\n",
    "    encoder__name = cat_encoder.__class__.__name__\n",
    "            # model = ComplementNB(norm=True,fit_prior=True,)\n",
    "    # model = MultinomialNB()\n",
    "    # model = LogisticRegression(n_jobs=-1, max_iter=10000,random_state=19)\n",
    "    model__name = model.__class__.__name__\n",
    "    pipe = Pipeline(steps=[('PW' + encoder__name, PolynomialWrapper(feature_encoder=cat_encoder)),\n",
    "                           (model__name,model )])\n",
    "    report = em.run(pipe) # Store A test log\n",
    "    print('PW' + encoder_name, model__name)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "\n",
    "# print(pipe)\n",
    "# wf_create(TargetEncoder(),RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b428290-d847-44c9-a9aa-7acfa29177aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "mdb = MongoClient()\n",
    "# mdb.list_database_names()\n",
    "class evaluate_model:\n",
    "    collector = mdb.ml_results.cv_results\n",
    "    \n",
    "    \n",
    "    def __init__(self, model, data=pd.DataFrame(), features=[]):\n",
    "        self.model = model\n",
    "        if data.shape[0]>0:\n",
    "            self.data = data\n",
    "        else:\n",
    "            self.data = pd.read_parquet('../data/final_data.parquet', engine='fastparquet')\n",
    "        if len(features)>0:\n",
    "            self.features = features\n",
    "        else:\n",
    "            self.features = list(self.data.columns)\n",
    "        self.train_idx, self.test_idx = gen_train_test(self.data, 1.0)\n",
    "        self.X_train = self.data.loc[self.train_idx, self.features]\n",
    "        self.y_train = self.data.target.loc[self.train_idx]\n",
    "        self.cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=5)\n",
    "        self.cv_results = None\n",
    "        self.legacy=0\n",
    "        \n",
    "        \n",
    "    def run(self, custom_model=None):\n",
    "        if custom_model:\n",
    "            selected_model = custom_model\n",
    "        else:\n",
    "            selected_model = self.model\n",
    "        with parallel_backend('threading'):\n",
    "            cv_results = cross_validate(selected_model,\n",
    "                                        self.X_train,\n",
    "                                        self.y_train,\n",
    "                                        cv=self.cv,\n",
    "                                        n_jobs=-1,\n",
    "                                        scoring=['f1_micro',\n",
    "                                                 'f1_macro',\n",
    "                                                 'f1_weighted',\n",
    "                                                 'precision_micro',\n",
    "                                                 'precision_macro',\n",
    "                                                 'precision_weighted',\n",
    "                                                 'recall_micro',\n",
    "                                                 'recall_macro',\n",
    "                                                 'recall_weighted'],return_train_score=True,return_estimator=True)\n",
    "                                        # error_score='raise',return_estimator=True)\n",
    "                                    ## Save this results\n",
    "        self.cv_results = cv_results\n",
    "        # cv_db.insert_one(cv_results)\n",
    "        # cnst = {'estimator_params': selected_model.get_params()}\n",
    "        record =  {}\n",
    "        record['estimator_params'] = str(selected_model.get_params())\n",
    "        \n",
    "        record['model_name'] = selected_model.__class__.__name__\n",
    "        record['features'] = list(self.features)\n",
    "        # record['data_idx'] = {'train_idx': list(self.train_idx),'test_idx': list(self.test_idx)}\n",
    "        # cnst['fit_time'] = list(cv_results['fit_time'])\n",
    "        for k,v in cv_results.items():\n",
    "            if k in ['estimator','fit_time','score_time']:\n",
    "                continue\n",
    "            else:\n",
    "                record[k] = v.mean()\n",
    "        # for _ in cv_db.find():\n",
    "        #     print(_.keys())\n",
    "        # print(record)\n",
    "        record['is_legacy_run'] = self.legacy\n",
    "        record['legacy_report'] = None\n",
    "        if self.legacy ==1:\n",
    "            # print(self.legacy_run())\n",
    "            l_rpt = self.legacy_run()\n",
    "            for k, v in l_rpt.items():\n",
    "                print(k)\n",
    "                print('~'*20)\n",
    "                print(v)\n",
    "                print(\"#\"*90)\n",
    "            record['legacy_report'] = l_rpt\n",
    "        \n",
    "        collector.insert_one(record)\n",
    "        \n",
    "        return cv_results\n",
    "    \n",
    "    \n",
    "    def plot(self):\n",
    "        sns.set()\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(18, 15))        \n",
    "        # fig.layout='constrained'\n",
    "\n",
    "        metrics = ['f1_micro', 'f1_macro', 'f1_weighted', 'precision_micro', 'precision_macro', 'precision_weighted', 'recall_micro', 'recall_macro', 'recall_weighted']\n",
    "        # for m  in metrics:\n",
    "        #     n = len(self.cv_results['test_'+m])\n",
    "        idx=0\n",
    "        for i in range(3):\n",
    "            n = len(self.cv_results['test_'+ metrics[0]])\n",
    "            for j in range(3):\n",
    "                axes[i,j].plot(range(n),self.cv_results['test_'+metrics[idx]],label=['test_'+metrics[idx]])\n",
    "                # axes[i,j].plot(range(n),self.cv_results['train_'+metrics[idx]],label=['train_'+metrics[idx]])\n",
    "                # axes[i,j].fill_between(range(n),self.cv_results['test_'+metrics[idx]],self.cv_results['train_'+metrics[idx]])\n",
    "                axes[i,j].legend()\n",
    "                axes[i,j].set_title(metrics[idx])\n",
    "                # axes[i,j].autoscale(enable=False)\n",
    "                idx+=1\n",
    "        plt.legend()\n",
    "    \n",
    "    \n",
    "    def plot_metric(self, metric):\n",
    "        ydata = self.cv_results['test_'+metric]\n",
    "        n = ydata.shape[0]\n",
    "        ffig = plt.plot(np.arange(n),ydata,)\n",
    "        fig = sns.regplot(x=np.arange(n), y=ydata)\n",
    "        plt.title(metric.upper())\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def switch_to_main_data(self):\n",
    "        if self.legacy==1:\n",
    "            print(\"#\"*100)\n",
    "            print(\"ALREADY ON LEGACY MODE\")\n",
    "            print(\"#\"*100)\n",
    "            return\n",
    "        self.legacy = 1\n",
    "        self.X_train_old = self.X_train\n",
    "        self.y_train_old = self.y_train\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data.loc[:,self.features], self.data.target)\n",
    "        print(\"#\"*100)\n",
    "        print(\"SWITCHING TO LEGACY MODE\")\n",
    "        print(\"#\"*100)\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        if self.legacy==0:\n",
    "            print(\"#\"*100)\n",
    "            print(\"NOT ON LEGACY MODE\")\n",
    "            print(\"#\"*100)\n",
    "            return\n",
    "        self.legacy = 0\n",
    "        self.X_train = self.X_train_old\n",
    "        self.y_train = self.y_train_old\n",
    "    \n",
    "    \n",
    "    def legacy_run(self):\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        self.legacy_report = {}\n",
    "        self.legacy_report['classification_report'] = classification_report(self.y_test, self.y_pred)\n",
    "        self.legacy_report['balanced_accuracy'] = sklearn.metrics.balanced_accuracy_score(self.y_test, self.y_pred)\n",
    "        return self.legacy_report\n",
    "\n",
    "    \n",
    "    def print_last_run_stat(self):\n",
    "        N = collector.estimated_document_count()\n",
    "        idx = 0\n",
    "        for c in collector.find(skip=N-1):\n",
    "            for k,v in c.items():\n",
    "                if 'f1_' in k and 'test' in k:\n",
    "                    print(k)\n",
    "                    print('~'*5)\n",
    "                    print(v)\n",
    "                    print('-'*20)\n",
    "            print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90017aa8-8188-474b-8762-3d51e2a2c143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_32</th>\n",
       "      <th>v_4</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_20</th>\n",
       "      <th>v_21</th>\n",
       "      <th>v_18</th>\n",
       "      <th>v_25</th>\n",
       "      <th>v_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>0.342246</td>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.303704</td>\n",
       "      <td>0.330484</td>\n",
       "      <td>0.325423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.333294</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.402597</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.303704</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.325423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.165736</td>\n",
       "      <td>0.298097</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.325423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.491817</td>\n",
       "      <td>0.306849</td>\n",
       "      <td>0.257746</td>\n",
       "      <td>0.429429</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.153847</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>0.279935</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.325423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.090920</td>\n",
       "      <td>0.306849</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.356164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>0.327450</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>0.570825</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.310811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>0.279935</td>\n",
       "      <td>0.083337</td>\n",
       "      <td>0.416665</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.429429</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.325301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.358650</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.325423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3796 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          v_32       v_4       v_3      v_20      v_21      v_18      v_25  \\\n",
       "id                                                                           \n",
       "0     0.212766  0.259259  0.362319  0.342246  0.303106  0.303704  0.330484   \n",
       "1     0.280000  0.333294  0.243243  0.235294  0.402597  0.276596  0.350000   \n",
       "2     0.425000  0.336207  0.288462  0.509804  0.303106  0.303704  0.294906   \n",
       "3     0.212766  0.165736  0.298097  0.305085  0.303106  0.301887  0.294906   \n",
       "4     0.451613  0.491817  0.306849  0.257746  0.429429  0.407407  0.153847   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3791  0.279935  0.371134  0.362319  0.305085  0.303106  0.301887  0.294906   \n",
       "3792  0.093750  0.090920  0.306849  0.450000  0.390625  0.157895  0.333333   \n",
       "3793  0.327450  0.534722  0.570825  0.130435  0.305556  0.470588  0.294906   \n",
       "3794  0.279935  0.083337  0.416665  0.266667  0.429429  0.541667  0.250000   \n",
       "3795  0.212766  0.336957  0.287234  0.305085  0.303106  0.358650  0.294906   \n",
       "\n",
       "          v_12  \n",
       "id              \n",
       "0     0.325423  \n",
       "1     0.352941  \n",
       "2     0.325423  \n",
       "3     0.325423  \n",
       "4     0.352941  \n",
       "...        ...  \n",
       "3791  0.325423  \n",
       "3792  0.356164  \n",
       "3793  0.310811  \n",
       "3794  0.325301  \n",
       "3795  0.325423  \n",
       "\n",
       "[3796 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.get_dummies(final_data_indvl_test.target)\n",
    "target_classes = list(labels.columns)\n",
    "# transformed_nominal = pd.DataFrame()\n",
    "nominal_data_indvl_transformed = final_data_indvl_test.loc[:,nominal]\n",
    "tr_nom_db = []\n",
    "for t_c in target_classes:\n",
    "    te = TargetEncoder(cols=nominal)\n",
    "    tmp = te.fit_transform(nominal_data_indvl_transformed, labels[t_c])\n",
    "    tr_nom_db.append((tmp,labels[t_c]))\n",
    "# tr_nom_db[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "765191c8-79d5-49cb-8a68-6f68cfcbf6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected= {0:[],\n",
    "                   1:[],\n",
    "                   2:[]}\n",
    "selectors = {0:[],\n",
    "            1:[],\n",
    "            2:[]}\n",
    "feature_selection_df = {0:None,\n",
    "                       1:None,\n",
    "                       2:None}\n",
    "feature_performance = {0:None,\n",
    "                       1:None,\n",
    "                       2:None}\n",
    "improvements = {0:[],\n",
    "                   1:[],\n",
    "                   2:[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee7968-881c-44d2-8706-f2504b31156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False,)\n",
    "encoded_nominal = ohe.fit_transform(bs.loc[:,nominal])\n",
    "# encoded_nominal[]\n",
    "enc_nom_df = pd.DataFrame(encoded_nominal,columns=ohe.get_feature_names_out())\n",
    "# final_data.shape\n",
    "enc_nom_df = enc_nom_df.loc[:3795, :]\n",
    "enc_nom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c741c76c-f129-4702-b060-9e95217d535f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c248ddd8-918e-4ce4-af1f-32212f2cf2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved By 0.0 on 0 Label\n",
      "0.7006145741878841\n",
      "Improved By 0.0 on 1 Label\n",
      "0.62071992976295\n",
      "Improved By 0.0 on 2 Label\n",
      "0.8103599648814751\n"
     ]
    }
   ],
   "source": [
    "from sklearnex.cluster import DBSCAN, KMeans     \n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.base import clone as model_clone\n",
    "from sklearnex.svm import NuSVC,SVR\n",
    "SVR\n",
    "\n",
    "\n",
    "        # model = \n",
    "estimator = LogisticRegression(solver='liblinear',n_jobs=-1,C=0.03,random_state=2, fit_intercept=False)\n",
    "# RFECV\n",
    "# features_selected = defaultdict(list)\n",
    "# selectors = []\n",
    "# for _ in range(5):\n",
    "try:\n",
    "    idx=0\n",
    "    for X, y in tr_nom_db:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(enc_nom_df,y,test_size=0.3,random_state=42)\n",
    "        model = model_clone(estimator)\n",
    "        model.fit(X_train,y_train)\n",
    "        acc_init = sklearn.metrics.f1_score(model.predict(X_test),y_test,average='micro')\n",
    "\n",
    "        # Reinitialise for RFE\n",
    "        # model = model_clone(estimator)\n",
    "\n",
    "        # model = RandomForestClassifier(n_jobs=-1)\n",
    "        # model.fit(X_train, y_train)\n",
    "        with parallel_backend('loky'):\n",
    "            selector = SequentialFeatureSelector(model_clone(estimator),tol=0.01,n_features_to_select='auto',cv=RepeatedStratifiedKFold(n_splits=3,n_repeats=2),n_jobs=-1,scoring='f1_micro',)\n",
    "            selector.fit(enc_nom_df, y)\n",
    "        # selectors[idx].append(selector)\n",
    "        # features_selected[idx].append(selector.support_)\n",
    "        model = model_clone(estimator)\n",
    "        model.fit(X_train,y_train)\n",
    "        acc_improved = sklearn.metrics.f1_score(model.predict(X_test),y_test,average='micro')\n",
    "        print(f\"Improved By {acc_improved - acc_init} on {idx} Label\")\n",
    "        improvements[idx].append(acc_improved-acc_init)\n",
    "        print(acc_improved)\n",
    "        idx+=1\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped Checking\")\n",
    "    # print(acc_improved)\n",
    "    print(acc_init)\n",
    "        # y_pred = \n",
    "    # features_selected\n",
    "    # # selectors\n",
    "    # # Nominal Feature Performance\n",
    "\n",
    "# for i in range(3):\n",
    "#     feature_selection_df[i] = pd.DataFrame(features_selected[i], columns=nominal)\n",
    "#     feature_performance[i] = feature_selection_df[i].mean(axis=0).round(2).to_dict()\n",
    "# pd.DataFrame(feature_performance).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a284f2e9-f04c-4cfe-b221-ac014f495155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6467334035827187"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### from sklearn.svm import LinearSVC\n",
    "lsvc =LinearSVC(random_state=2,C=100,tol=0.0000001,fit_intercept=False)\n",
    "lsvc.fit(enc_nom_df,data.target)\n",
    "lsvc.score(enc_nom_df,data.target)\n",
    "SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354921ba-8815-452d-862e-15e58d4a2be3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Decision Tree Based RFECV results using RepeatedStratifiedKFold\n",
    "<style type=\"text/css\">\n",
    "</style>\n",
    "<table id=\"T_bcf22\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th class=\"blank level0\" >&nbsp;</th>\n",
    "      <th id=\"T_bcf22_level0_col0\" class=\"col_heading level0 col0\" >v_32</th>\n",
    "      <th id=\"T_bcf22_level0_col1\" class=\"col_heading level0 col1\" >v_4</th>\n",
    "      <th id=\"T_bcf22_level0_col2\" class=\"col_heading level0 col2\" >v_3</th>\n",
    "      <th id=\"T_bcf22_level0_col3\" class=\"col_heading level0 col3\" >v_20</th>\n",
    "      <th id=\"T_bcf22_level0_col4\" class=\"col_heading level0 col4\" >v_21</th>\n",
    "      <th id=\"T_bcf22_level0_col5\" class=\"col_heading level0 col5\" >v_18</th>\n",
    "      <th id=\"T_bcf22_level0_col6\" class=\"col_heading level0 col6\" >v_25</th>\n",
    "      <th id=\"T_bcf22_level0_col7\" class=\"col_heading level0 col7\" >v_12</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th id=\"T_bcf22_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
    "      <td id=\"T_bcf22_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
    "      <td id=\"T_bcf22_row0_col1\" class=\"data row0 col1\" >0.910000</td>\n",
    "      <td id=\"T_bcf22_row0_col2\" class=\"data row0 col2\" >0.880000</td>\n",
    "      <td id=\"T_bcf22_row0_col3\" class=\"data row0 col3\" >0.260000</td>\n",
    "      <td id=\"T_bcf22_row0_col4\" class=\"data row0 col4\" >0.120000</td>\n",
    "      <td id=\"T_bcf22_row0_col5\" class=\"data row0 col5\" >0.700000</td>\n",
    "      <td id=\"T_bcf22_row0_col6\" class=\"data row0 col6\" >0.420000</td>\n",
    "      <td id=\"T_bcf22_row0_col7\" class=\"data row0 col7\" >0.020000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_bcf22_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
    "      <td id=\"T_bcf22_row1_col0\" class=\"data row1 col0\" >0.020000</td>\n",
    "      <td id=\"T_bcf22_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
    "      <td id=\"T_bcf22_row1_col2\" class=\"data row1 col2\" >0.330000</td>\n",
    "      <td id=\"T_bcf22_row1_col3\" class=\"data row1 col3\" >0.020000</td>\n",
    "      <td id=\"T_bcf22_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
    "      <td id=\"T_bcf22_row1_col5\" class=\"data row1 col5\" >0.020000</td>\n",
    "      <td id=\"T_bcf22_row1_col6\" class=\"data row1 col6\" >0.020000</td>\n",
    "      <td id=\"T_bcf22_row1_col7\" class=\"data row1 col7\" >0.000000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_bcf22_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
    "      <td id=\"T_bcf22_row2_col0\" class=\"data row2 col0\" >1.000000</td>\n",
    "      <td id=\"T_bcf22_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
    "      <td id=\"T_bcf22_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
    "      <td id=\"T_bcf22_row2_col3\" class=\"data row2 col3\" >0.910000</td>\n",
    "      <td id=\"T_bcf22_row2_col4\" class=\"data row2 col4\" >0.650000</td>\n",
    "      <td id=\"T_bcf22_row2_col5\" class=\"data row2 col5\" >1.000000</td>\n",
    "      <td id=\"T_bcf22_row2_col6\" class=\"data row2 col6\" >1.000000</td>\n",
    "      <td id=\"T_bcf22_row2_col7\" class=\"data row2 col7\" >0.440000</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132fd95-64fb-4b57-9b8a-9693c17d72bc",
   "metadata": {},
   "source": [
    "#### Logistic Regression Based RFECV results using RepeatedStratifiedKFold\n",
    "<style type=\"text/css\">\n",
    "</style>\n",
    "<table id=\"T_2e2bf\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th class=\"blank level0\" >&nbsp;</th>\n",
    "      <th id=\"T_2e2bf_level0_col0\" class=\"col_heading level0 col0\" >v_32</th>\n",
    "      <th id=\"T_2e2bf_level0_col1\" class=\"col_heading level0 col1\" >v_4</th>\n",
    "      <th id=\"T_2e2bf_level0_col2\" class=\"col_heading level0 col2\" >v_3</th>\n",
    "      <th id=\"T_2e2bf_level0_col3\" class=\"col_heading level0 col3\" >v_20</th>\n",
    "      <th id=\"T_2e2bf_level0_col4\" class=\"col_heading level0 col4\" >v_21</th>\n",
    "      <th id=\"T_2e2bf_level0_col5\" class=\"col_heading level0 col5\" >v_18</th>\n",
    "      <th id=\"T_2e2bf_level0_col6\" class=\"col_heading level0 col6\" >v_25</th>\n",
    "      <th id=\"T_2e2bf_level0_col7\" class=\"col_heading level0 col7\" >v_12</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th id=\"T_2e2bf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
    "      <td id=\"T_2e2bf_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row0_col2\" class=\"data row0 col2\" >0.970000</td>\n",
    "      <td id=\"T_2e2bf_row0_col3\" class=\"data row0 col3\" >0.970000</td>\n",
    "      <td id=\"T_2e2bf_row0_col4\" class=\"data row0 col4\" >0.100000</td>\n",
    "      <td id=\"T_2e2bf_row0_col5\" class=\"data row0 col5\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row0_col6\" class=\"data row0 col6\" >0.970000</td>\n",
    "      <td id=\"T_2e2bf_row0_col7\" class=\"data row0 col7\" >0.170000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_2e2bf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
    "      <td id=\"T_2e2bf_row1_col0\" class=\"data row1 col0\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row1_col3\" class=\"data row1 col3\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row1_col4\" class=\"data row1 col4\" >0.230000</td>\n",
    "      <td id=\"T_2e2bf_row1_col5\" class=\"data row1 col5\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row1_col7\" class=\"data row1 col7\" >0.570000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_2e2bf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
    "      <td id=\"T_2e2bf_row2_col0\" class=\"data row2 col0\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row2_col4\" class=\"data row2 col4\" >0.130000</td>\n",
    "      <td id=\"T_2e2bf_row2_col5\" class=\"data row2 col5\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row2_col6\" class=\"data row2 col6\" >1.000000</td>\n",
    "      <td id=\"T_2e2bf_row2_col7\" class=\"data row2 col7\" >0.300000</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "952c3f76-439d-462b-a057-92225d1c04c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6]),)\n",
      "(array([0, 1, 2, 3, 4, 5, 6]),)\n",
      "(array([0, 1, 2, 3, 4, 5, 6]),)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# SequentialFeatureSelector()\n",
    "for dataset,fset in zip(features_selected):\n",
    "    np.where(fset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ba0ff-edfb-440f-ae82-c85bb46471ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import MEstimateEncoder\n",
    "\n",
    "\n",
    "ovr_pipe = Pipeline(steps=[(encoder_name,cat_encoder), (model__name, model)])\n",
    "                           \n",
    "# ovr_pipe\n",
    "ovr = OneVsRestClassifier(ovr_pipe)\n",
    "# ovr\n",
    "# pipe\n",
    "# print(pipe)\n",
    "d_coll = []\n",
    "try:\n",
    "    for m_ in tqdm(np.linspace(0.1,1.5,num=20)):\n",
    "        cat_encoder = TargetEncoder(drop_invariant=False,cols=['v_32','v_4','v_3','v_20','v_21','v_18','v_25','v_12'],smoothing=m_)\n",
    "        encoder_name = cat_encoder.__class__.__name__\n",
    "        # model = ComplementNB(norm=True,fit_prior=True,)\n",
    "        model = MultinomialNB()\n",
    "        model = LogisticRegression(n_jobs=-1, max_iter=10000,random_state=19)\n",
    "        model__name = model.__class__.__name__\n",
    "        pipe = Pipeline(steps=[('PW' + encoder_name, PolynomialWrapper(feature_encoder=cat_encoder)),\n",
    "                               (model__name,model )])\n",
    "\n",
    "        report = em.run(pipe)\n",
    "        print(report['test_f1_macro'].mean())\n",
    "        d_coll.append((m_,report['test_f1_macro'].mean(), report['test_f1_macro'].std(), report['test_f1_macro'].max()))\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted, Plotting calculated values only\")\n",
    "# pipe = make\n",
    "def plot_m_variance(d_coll):\n",
    "    sns.set()\n",
    "    ddx= [x for x,y,u,r in d_coll]\n",
    "    ddc = [y for x,y,u,r in d_coll]\n",
    "    ddep = [y+u for x,y,u,r in d_coll]\n",
    "    dden = [y-u for x,y,u,r in d_coll]\n",
    "    ddem = [r for x,y,u,r in d_coll]\n",
    "    plt.plot(ddx,ddc,'b',label=\"\\u00b5\")\n",
    "    plt.plot(ddx,ddep,'r',label=\"\\u03c3\"+\"+\")\n",
    "    plt.plot(ddx,dden,'g',label=\"\\u03c3\"+\"-\")\n",
    "    plt.plot(ddx,ddem,'y',label=\"\\u03c3\"+\"max\")\n",
    "    fig=plt.fill_between(ddx,ddep,dden,alpha=0.5)\n",
    "    fig = plt.legend()\n",
    "plot_m_variance(d_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1532766a-4cb7-4149-95f7-2446c263b36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5419    0\n",
       "5420    1\n",
       "5421    0\n",
       "5422    1\n",
       "5423    1\n",
       "Name: target, Length: 5424, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (autoskl)",
   "language": "python",
   "name": "autoskl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
