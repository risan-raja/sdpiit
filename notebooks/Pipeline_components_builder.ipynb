{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f3c0459-482d-4867-8f09-ba1723a13fac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "import warnings\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import (\n",
    "    BackwardDifferenceEncoder,\n",
    "    BaseNEncoder,\n",
    "    BinaryEncoder,\n",
    "    CatBoostEncoder,\n",
    "    CountEncoder,\n",
    "    GLMMEncoder,\n",
    "    HelmertEncoder,\n",
    "    JamesSteinEncoder,\n",
    "    LeaveOneOutEncoder,\n",
    "    MEstimateEncoder,\n",
    "    QuantileEncoder,\n",
    "    SummaryEncoder,\n",
    "    TargetEncoder,\n",
    "    WOEEncoder,\n",
    ")\n",
    "from sklearn import set_config\n",
    "from sklearn.base import clone as model_clone\n",
    "from sklearn.cluster import *\n",
    "from sklearn.compose import *\n",
    "from sklearn.cross_decomposition import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.gaussian_process import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.multioutput import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.utils import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.semi_supervised import *\n",
    "from sklearn.discriminant_analysis import *\n",
    "import sklearnex, daal4py\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "from sklearn.calibration import *\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pd.options.display.max_columns = 50\n",
    "set_config(display=\"diagram\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import parallel_backend\n",
    "from joblib.memory import Memory\n",
    "\n",
    "sns.set()\n",
    "from pprint import pprint\n",
    "from helpers import PolynomialWrapper as PWrapper\n",
    "from helpers import NestedCVWrapper as NCVWrapper\n",
    "from helpers import ColumnSelectors\n",
    "import sklearn\n",
    "from helpers import DFCollection\n",
    "from helpers import plot_mean_std_max\n",
    "from helpers import CustomMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebac6f9-6fad-4c50-bdc9-ab04d2613cfa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_names = [\n",
    "    sklearn.ensemble._weight_boosting.AdaBoostClassifier,\n",
    "    sklearn.naive_bayes.BernoulliNB,\n",
    "    # sklearn.naive_bayes.CategoricalNB,\n",
    "    # sklearn.naive_bayes.ComplementNB,\n",
    "    sklearn.tree._classes.DecisionTreeClassifier,\n",
    "    sklearn.tree._classes.ExtraTreeClassifier,\n",
    "    sklearn.ensemble._forest.ExtraTreesClassifier,\n",
    "    sklearn.naive_bayes.GaussianNB,\n",
    "    # sklearn.gaussian_process._gpc.GaussianProcessClassifier,\n",
    "    sklearn.ensemble._gb.GradientBoostingClassifier,\n",
    "    sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier,\n",
    "    sklearn.neighbors.KNeighborsClassifier,\n",
    "    sklearn.svm._classes.LinearSVC,\n",
    "    sklearn.linear_model.LogisticRegression,\n",
    "    # sklearn.linear_model._logistic.LogisticRegressionCV,\n",
    "    # sklearn.neural_network._multilayer_perceptron.MLPClassifier,\n",
    "    sklearn.naive_bayes.MultinomialNB,\n",
    "    # sklearn.neighbors._nearest_centroid.NearestCentroid,\n",
    "    sklearn.svm.NuSVC,\n",
    "    sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier,\n",
    "    sklearn.linear_model._perceptron.Perceptron,\n",
    "    # sklearn.neighbors._classification.RadiusNeighborsClassifier,\n",
    "    sklearn.ensemble._forest.RandomForestClassifier,\n",
    "    sklearn.linear_model._ridge.RidgeClassifier,\n",
    "    # sklearn.linear_model._ridge.RidgeClassifierCV,\n",
    "    sklearn.linear_model._stochastic_gradient.SGDClassifier,\n",
    "    sklearn.svm.SVC,\n",
    "]\n",
    "db = DFCollection()\n",
    "column_selector = ColumnSelectors()\n",
    "classifiers = [f() for f in cls_names]\n",
    "dtype_info = column_selector.dtype_info\n",
    "ordinal = column_selector.ordinal_cols\n",
    "nominal = column_selector.nominal_cols\n",
    "binary = column_selector.binary_cols\n",
    "ratio = column_selector.ratio_cols\n",
    "\n",
    "\n",
    "final_data = db.final_data\n",
    "final_pred_data = db.final_pred_data\n",
    "baseline_prediction_data = db.baseline_prediction_data\n",
    "data_logit = db.data_logits\n",
    "prediction_data = db.prediction_data\n",
    "master_data = db.master\n",
    "given_data = db.data\n",
    "\n",
    "ordinal_data, nominal_data, binary_data, ratio_data = db.categorise_data()\n",
    "\n",
    "\n",
    "def gen_balanced_trained_test(data, p):\n",
    "    Y = data.target\n",
    "    X_2 = Y_2 = Y[Y == 2].index\n",
    "    X_0 = Y_0 = Y[Y == 0].index\n",
    "    X_1 = Y_1 = Y[Y == 1].index\n",
    "    train_size = int(p * Y_2.shape[0])\n",
    "    test_size = int((1 - p) * Y_2.shape[0])\n",
    "\n",
    "    train_idx_2 = np.random.choice(Y_2, (train_size,))\n",
    "    train_idx_1 = np.random.choice(Y_1, (train_size,))\n",
    "    train_idx_0 = np.random.choice(Y_0, (train_size,))\n",
    "    train_idx = np.r_[train_idx_0, train_idx_1, train_idx_2]\n",
    "    # train_idx.shape\n",
    "\n",
    "    test_idx_2 = np.random.choice(np.setdiff1d(Y_2, train_idx_2), (test_size,))\n",
    "    test_idx_1 = np.random.choice(np.setdiff1d(Y_1, train_idx_1), (test_size,))\n",
    "    test_idx_0 = np.random.choice(np.setdiff1d(Y_0, train_idx_0), (test_size,))\n",
    "    test_idx = np.r_[test_idx_0, test_idx_1, test_idx_2]\n",
    "    # test_idx.shape\n",
    "    return train_idx, test_idx\n",
    "\n",
    "\n",
    "def gen_nominal_maps(bs: pd.DataFrame = master_data) -> tuple[defaultdict, defaultdict]:\n",
    "    nominal_master_db = bs.loc[:, nominal]\n",
    "    nominal_cont_map = defaultdict(dict)\n",
    "    nominal_indvl_map = defaultdict(dict)\n",
    "    for c in nominal:\n",
    "        un = sorted(nominal_master_db[c].unique().tolist())\n",
    "        n = len(un)\n",
    "        new_id = list(range(n))\n",
    "        nominal_indvl_map[c] = dict(zip(un, new_id))\n",
    "    start = 0\n",
    "    for c in nominal:\n",
    "        un = sorted(nominal_master_db[c].unique().tolist())\n",
    "        n = len(un)\n",
    "        new_id = list(range(start, start + n))\n",
    "        nominal_cont_map[c] = dict(zip(un, new_id))\n",
    "        start += n\n",
    "    return nominal_indvl_map, nominal_cont_map\n",
    "\n",
    "\n",
    "# nominal_indvl_map, nominal_cont_map = gen_nominal_maps()\n",
    "# nominal_master_db = bs.loc[:, nominal]\n",
    "\n",
    "# nominal_master_db_indvl = nominal_master_db.copy()\n",
    "# nominal_master_db_cont = nominal_master_db.copy()\n",
    "\n",
    "\n",
    "# nominal_indvl_map\n",
    "def nm_indvl_data_trnsform(row):\n",
    "    for c in nominal:\n",
    "        curr = row[c]\n",
    "        row[c] = nominal_indvl_map[c][curr]\n",
    "    return row\n",
    "\n",
    "\n",
    "# test1_nominal = nominal_master_db_indvl.apply(nm_indvl_data_trnsform, axis=1)\n",
    "\n",
    "\n",
    "def nm_cont_data_trnsform(row):\n",
    "    for c in nominal:\n",
    "        curr = row[c]\n",
    "        row[c] = nominal_cont_map[c][curr]\n",
    "    return row\n",
    "\n",
    "\n",
    "# test2_nominal = nominal_master_db_cont.apply(nm_cont_data_trnsform, axis=1)\n",
    "# prediction_data = pd.read_pickle(\"../data/pred_data.pkl\")\n",
    "# est_ = [(\"cnb\",CategoricalNB()),]\n",
    "\n",
    "\n",
    "def wf_create(cat_encoder=TargetEncoder, model=None):\n",
    "    \"\"\"\n",
    "    :param cat_encoder: category_encoders\n",
    "    :param model: scikit-learn Model\n",
    "    :return pipe: sklearn.pipeline.Pipline\n",
    "    Examples of model param:\n",
    "\n",
    "    model = ComplementNB(norm=True,fit_prior=True,)\n",
    "    model = MultinomialNB()\n",
    "    model = LogisticRegression(n_jobs=-1, max_iter=10000,random_state=19)\n",
    "    \"\"\"\n",
    "    _steps = []\n",
    "    encoder__name = cat_encoder.__class__.__name__\n",
    "    _steps.append(\n",
    "        (\"PW\" + encoder__name, PolynomialWrapper(feature_encoder=cat_encoder))\n",
    "    )\n",
    "    if model is None:\n",
    "        passordinal_columns\n",
    "    else:\n",
    "        model__name = model.__class__.__name__\n",
    "        _steps.append((model__name, model))\n",
    "    pipe = Pipeline(steps=_steps)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84be34c5-7688-44ca-a1ff-997c325ac06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    AdaBoostClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    BernoulliNB(),\n",
    "    CalibratedClassifierCV(),\n",
    "    CategoricalNB(),\n",
    "    ComplementNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    DummyClassifier(),\n",
    "    ExtraTreeClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    GaussianNB(),\n",
    "    GaussianProcessClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    HistGradientBoostingClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    LabelPropagation(),\n",
    "    LabelSpreading(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    LinearSVC(),\n",
    "    LogisticRegression(),\n",
    "    LogisticRegressionCV(),\n",
    "    MLPClassifier(),\n",
    "    MultinomialNB(),\n",
    "    NearestCentroid(),\n",
    "    NuSVC(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    Perceptron(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    RadiusNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    RidgeClassifier(),\n",
    "    RidgeClassifierCV(),\n",
    "    SGDClassifier(),\n",
    "    SVC(),\n",
    "]\n",
    "\n",
    "\n",
    "# combiners = [sklearn.multioutput.ClassifierChain,\n",
    "#  sklearn.multioutput.MultiOutputClassifier,\n",
    "#  sklearn.multiclass.OneVsOneClassifier,\n",
    "#  sklearn.multiclass.OneVsRestClassifier,\n",
    "#  sklearn.multiclass.OutputCodeClassifier,\n",
    "#  sklearn.ensemble._stacking.StackingClassifier,\n",
    "#  sklearn.ensemble._voting.VotingClassifier\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aaef3d1-845c-4838-8dca-d72ddd4ea644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdaBoostClassifier(),\n",
       " BaggingClassifier(),\n",
       " BernoulliNB(),\n",
       " CalibratedClassifierCV(),\n",
       " CategoricalNB(),\n",
       " ComplementNB(),\n",
       " DecisionTreeClassifier(),\n",
       " DummyClassifier(),\n",
       " ExtraTreeClassifier(),\n",
       " ExtraTreesClassifier(),\n",
       " GaussianNB(),\n",
       " GaussianProcessClassifier(),\n",
       " GradientBoostingClassifier(),\n",
       " HistGradientBoostingClassifier(),\n",
       " KNeighborsClassifier(),\n",
       " LabelPropagation(),\n",
       " LabelSpreading(),\n",
       " LinearDiscriminantAnalysis(),\n",
       " LinearSVC(),\n",
       " LogisticRegression(),\n",
       " LogisticRegressionCV(),\n",
       " MLPClassifier(),\n",
       " MultinomialNB(),\n",
       " NearestCentroid(),\n",
       " NuSVC(),\n",
       " PassiveAggressiveClassifier(),\n",
       " Perceptron(),\n",
       " QuadraticDiscriminantAnalysis(),\n",
       " RadiusNeighborsClassifier(),\n",
       " RandomForestClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifierCV(),\n",
       " SGDClassifier(),\n",
       " SVC()]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e38866-69d8-4956-91ac-cf8c3abeef15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (autoskl)",
   "language": "python",
   "name": "autoskl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
