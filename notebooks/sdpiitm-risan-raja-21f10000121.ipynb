{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import (\n",
    "    BackwardDifferenceEncoder,\n",
    "    BaseNEncoder,\n",
    "    BinaryEncoder,\n",
    "    CatBoostEncoder,\n",
    "    CountEncoder,\n",
    "    GLMMEncoder,\n",
    "    HelmertEncoder,\n",
    "    JamesSteinEncoder,\n",
    "    LeaveOneOutEncoder,\n",
    "    MEstimateEncoder,\n",
    "    SummaryEncoder,\n",
    "    TargetEncoder,\n",
    "    WOEEncoder,\n",
    ")\n",
    "from sklearn import set_config\n",
    "from sklearn.base import clone as model_clone\n",
    "from sklearn.cluster import *\n",
    "from sklearn.compose import *\n",
    "from sklearn.cross_decomposition import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.gaussian_process import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.multioutput import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.utils import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.semi_supervised import *\n",
    "from sklearn.discriminant_analysis import *\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "\n",
    "from sklearn.calibration import *\n",
    "import joblib\n",
    "pd.options.display.max_columns = 50\n",
    "set_config(display=\"diagram\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from joblib import parallel_backend\n",
    "from joblib.memory import Memory\n",
    "def allow_stopping(func):\n",
    "    def wrapper():\n",
    "        try:\n",
    "            value = func()\n",
    "            return value\n",
    "            # gc.collect()\n",
    "        except KeyboardInterrupt as e:\n",
    "            print(\"Program Stopped\")\n",
    "        gc.collect()\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "__refresh__ = 0\n",
    "\n",
    "def run_if_refresh(func):\n",
    "    def wrapper():\n",
    "        global __refresh__\n",
    "        if __refresh__ == 1:\n",
    "            value = func()\n",
    "        else:\n",
    "            print(\"Using Cache, Set Refresh to '__refresh__=1' to regenerate this function\")\n",
    "        return value\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    ColumnSelectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnSelectors:\n",
    "    def __init__(self, default=None):\n",
    "        self.dtype_info = {\n",
    "            \"binary__v_1\": \"Binary\",\n",
    "            \"binary__v_11\": \"Binary\",\n",
    "            \"binary__v_14\": \"Binary\",\n",
    "            \"binary__v_26\": \"Binary\",\n",
    "            \"binary__v_27\": \"Binary\",\n",
    "            \"binary__v_28\": \"Binary\",\n",
    "            \"binary__v_30\": \"Binary\",\n",
    "            \"binary__v_9\": \"Binary\",\n",
    "            \"nominal__v_12\": \"Nominal\",\n",
    "            \"nominal__v_18\": \"Nominal\",\n",
    "            \"nominal__v_20\": \"Nominal\",\n",
    "            \"nominal__v_21\": \"Nominal\",\n",
    "            \"nominal__v_25\": \"Nominal\",\n",
    "            \"nominal__v_3\": \"Nominal\",\n",
    "            \"nominal__v_32\": \"Nominal\",\n",
    "            \"nominal__v_4\": \"Nominal\",\n",
    "            \"ordinal__v_0\": \"Ordinal\",\n",
    "            \"ordinal__v_10\": \"Ordinal\",\n",
    "            \"ordinal__v_13\": \"Ordinal\",\n",
    "            \"ordinal__v_15\": \"Ordinal\",\n",
    "            \"ordinal__v_17\": \"Ordinal\",\n",
    "            \"ordinal__v_19\": \"Ordinal\",\n",
    "            \"ordinal__v_22\": \"Ordinal\",\n",
    "            \"ordinal__v_23\": \"Ordinal\",\n",
    "            \"ordinal__v_24\": \"Ordinal\",\n",
    "            \"ordinal__v_29\": \"Ordinal\",\n",
    "            \"ordinal__v_31\": \"Ordinal\",\n",
    "            \"ordinal__v_33\": \"Ordinal\",\n",
    "            \"ordinal__v_5\": \"Ordinal\",\n",
    "            \"ordinal__v_6\": \"Ordinal\",\n",
    "            \"ratio__v_16\": \"Ratio\",\n",
    "            \"ratio__v_2\": \"Ratio\",\n",
    "            \"ratio__v_34\": \"Ratio\",\n",
    "            \"ratio__v_35\": \"Ratio\",\n",
    "            \"ratio__v_36\": \"Ratio\",\n",
    "            \"ratio__v_37\": \"Ratio\",\n",
    "            \"ratio__v_38\": \"Ratio\",\n",
    "            \"ratio__v_39\": \"Ratio\",\n",
    "            \"ratio__v_40\": \"Ratio\",\n",
    "            \"ratio__v_7\": \"Ratio\",\n",
    "            \"ratio__v_8\": \"Ratio\",\n",
    "        }\n",
    "\n",
    "        self.ordinal_cols = [\n",
    "            i for i in self.dtype_info if self.dtype_info[i] == \"Ordinal\"\n",
    "        ]\n",
    "        self.nominal_cols = [\n",
    "            i for i in self.dtype_info if self.dtype_info[i] == \"Nominal\"\n",
    "        ]\n",
    "        self.binary_cols = [\n",
    "            i for i in self.dtype_info if self.dtype_info[i] == \"Binary\"\n",
    "        ]\n",
    "        self.ratio_cols = [i for i in self.dtype_info if self.dtype_info[i] == \"Ratio\"]\n",
    "        self.ordinal = make_column_selector(\n",
    "            pattern=\"|\".join(self.ordinal_cols),\n",
    "        )\n",
    "        self.nominal = make_column_selector(\n",
    "            pattern=\"|\".join(self.nominal_cols),\n",
    "        )\n",
    "        self.binary = make_column_selector(\n",
    "            pattern=\"|\".join(self.binary_cols),\n",
    "        )\n",
    "        self.ratio = make_column_selector(\n",
    "            pattern=\"|\".join(self.ratio_cols),\n",
    "        )\n",
    "\n",
    "    def ordinal_selector(self):\n",
    "        return self.ordinal\n",
    "\n",
    "    def nominal_selector(self):\n",
    "        return self.nominal\n",
    "\n",
    "    def binary_selector(self):\n",
    "        return self.binary\n",
    "\n",
    "    def ratio_selector(self):\n",
    "        return self.ratio\n",
    "\n",
    "column_directory = ColumnSelectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data and Execution Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH=\"/kaggle/input/students-drop-out-prediction/\"\n",
    "DATA_SAVE_PATH='/kaggle/working/'\n",
    "TRAIN_DATA='train.csv'\n",
    "TEST_DATA='test.csv'\n",
    "KAGGLE_ENV =1\n",
    "__refresh__ = 0\n",
    "\n",
    "cwd = os.path.abspath(os.getcwd())\n",
    "if 'mlop3n/Pycharm' in cwd:\n",
    "    KAGGLE_ENV = 0\n",
    "\n",
    "if KAGGLE_ENV == 0:\n",
    "    LOCAL_PATH = '../data'\n",
    "    DATA_PATH = LOCAL_PATH + DATA_PATH\n",
    "    DATA_SAVE_PATH= LOCAL_PATH + DATA_SAVE_PATH\n",
    "    \n",
    "def rename_columns_with_dtype(DATA_PATH=DATA_PATH,DATA_SAVE_PATH=DATA_SAVE_PATH):\n",
    "    raw_data = pd.read_csv(DATA_PATH+TRAIN_DATA,index_col=0)\n",
    "    raw_data_eval = pd.read_csv(DATA_PATH+TEST_DATA,index_col=0)\n",
    "\n",
    "    raw_dtypes_info = {}\n",
    "    saved_dtypes_info = column_directory.dtype_info\n",
    "    for k, v in saved_dtypes_info.items():\n",
    "        tmp = k.split('__')\n",
    "        data_type = tmp[0]\n",
    "        column_name = tmp[1]\n",
    "        raw_dtypes_info[column_name] = k\n",
    "\n",
    "    raw_data.rename(columns=raw_dtypes_info,inplace=True)\n",
    "    raw_data_eval.rename(columns=raw_dtypes_info,inplace=True)\n",
    "    raw_data.to_parquet(DATA_SAVE_PATH+'train.parquet')\n",
    "    raw_data_eval.to_parquet(DATA_SAVE_PATH+'test.parquet')\n",
    "\n",
    "if __refresh__ == 1:\n",
    "    rename_columns_with_dtype()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###    Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DFCollection:\n",
    "    \"\"\"\n",
    "    Contains all the data used.\n",
    "    Upon Init all data gets loaded.\n",
    "    Save method is also provided.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.c_sel = ColumnSelectors()\n",
    "\n",
    "        self.file_path = \"/kaggle/working/\"\n",
    "        if KAGGLE_ENV == 0:\n",
    "            self.file_path = '../data'+ self.file_path\n",
    "        self.data = pd.read_parquet(\n",
    "            self.file_path + \"train.parquet\"\n",
    "        )\n",
    "        self.prediction_data = pd.read_parquet(\n",
    "            self.file_path + \"test.parquet\"\n",
    "        )\n",
    "        self.data_logits = pd.read_parquet(\n",
    "            self.file_path + \"data_with_ridit.hdfs\"\n",
    "        )\n",
    "        self.final_data = pd.read_parquet(\n",
    "            self.file_path + \"final_data.parquet\"\n",
    "        )\n",
    "        self.final_pred_data = pd.read_parquet(\n",
    "            self.file_path + \"final_pred_data.parquet\"\n",
    "        )\n",
    "        \n",
    "        self.core_frames = [\n",
    "            self.data,\n",
    "            self.prediction_data,\n",
    "            self.data_logits,\n",
    "            self.final_data,\n",
    "\n",
    "        ]\n",
    "        save_paths = [\n",
    "            \"train.parquet\",\n",
    "            \"test.parquet\",\n",
    "            \"data_with_ridit.hdfs\",\n",
    "            \"final_data.parquet\",\n",
    "            \"final_pred_data.parquet\",\n",
    "        ]\n",
    "        self.save_paths = [self.file_path + x for x in save_paths]\n",
    "        self.core_names = [x.split(\".\")[0] for x in self.save_paths]\n",
    "        self.final_data.rename(columns={\"label\": \"target\"}, inplace=True)\n",
    "        self.data.rename(columns={\"label\": \"target\"}, inplace=True)\n",
    "        self.nominal_categories = {}\n",
    "        for nc in self.c_sel.nominal_cols:\n",
    "            ncs = self.master.loc[:, nc].unique()\n",
    "            self.nominal_categories[nc] = ncs\n",
    "\n",
    "        self.ordinal_categories = {}\n",
    "        for nc in self.c_sel.ordinal_cols:\n",
    "            ncs = self.master.loc[:, nc].unique()\n",
    "            self.ordinal_categories[nc] = ncs\n",
    "\n",
    "    @staticmethod\n",
    "    def __save__(df: pd.DataFrame, loc: str):\n",
    "        try:\n",
    "            df.to_parquet(loc)\n",
    "        except:\n",
    "            return \"Save Failed\"\n",
    "        return \"Saved Successfully\"\n",
    "\n",
    "    def save_all(self):\n",
    "        \"\"\"\n",
    "        Before Saving all objects ask question for each of them.\n",
    "        And for each question if the answer is yes proceed to save otherwise continue.\n",
    "        \"\"\"\n",
    "        exit_msg = \"Exiting!\"\n",
    "        try:\n",
    "            for df_name, df, df_loc in zip(\n",
    "                self.core_names, self.core_frames, self.save_paths\n",
    "            ):\n",
    "                base_question = f\"Do you want to save {df_name}?(Yes/No/Exit)\"\n",
    "                skip_msg = f\"Skipping {df_name}\"\n",
    "                while True:\n",
    "                    answer = input(base_question)\n",
    "                    if answer == \"Yes\":\n",
    "                        msg = self.__save__(df, df_loc)\n",
    "                        print(df_name + msg)\n",
    "                        break\n",
    "                    elif answer in [\"No\", \"n\"]:\n",
    "                        print(skip_msg)\n",
    "                        break\n",
    "                    elif answer in [\"Exit\", \"e\"]:\n",
    "                        print(exit_msg)\n",
    "                        return\n",
    "                    else:\n",
    "                        print(\"Not Valid Input\")\n",
    "                        continue\n",
    "        except KeyboardInterrupt:\n",
    "            print(exit_msg)\n",
    "            return\n",
    "\n",
    "    def categorise_data(self, df: pd.DataFrame = None):\n",
    "\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            ordinal_data = df.loc[:, self.c_sel.ordinal_cols]\n",
    "            nominal_data = df.loc[:, self.c_sel.nominal_cols]\n",
    "            binary_data = df.loc[:, self.c_sel.binary_cols]\n",
    "            ratio_data = df.loc[:, self.c_sel.ratio_cols]\n",
    "        else:\n",
    "            df = self.final_data\n",
    "            ordinal_data = df.loc[:, self.c_sel.ordinal_cols]\n",
    "            nominal_data = df.loc[:, self.c_sel.nominal_cols]\n",
    "            binary_data = df.loc[:, self.c_sel.binary_cols]\n",
    "            ratio_data = df.loc[:, self.c_sel.ratio_cols]\n",
    "        return ordinal_data, nominal_data, binary_data, ratio_data\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     db = DFCollection()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (autoskl)",
   "language": "python",
   "name": "autoskl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
