{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd242bb2-25e0-4775-81ee-7082e2eaa992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-11T13:48:22.841701Z",
     "iopub.status.busy": "2022-09-11T13:48:22.841010Z",
     "iopub.status.idle": "2022-09-11T13:49:55.603665Z",
     "shell.execute_reply": "2022-09-11T13:49:55.602460Z",
     "shell.execute_reply.started": "2022-09-11T13:48:22.841573Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from setup_transform.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# import widen_notebook\n",
    "from mysetup import NotebookFinder\n",
    "import sys\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "\n",
    "from setup_transform import *\n",
    "\n",
    "%matplotlib inline\n",
    "cl_weight = sklearn.utils.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=[0, 1, 2], y=y\n",
    ")\n",
    "CLASS_WEIGHTS = {i: cl_weight[i] for i in range(3)}\n",
    "def_cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=5, random_state=42)\n",
    "lgr_params = dict(\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    "    fit_intercept=False,\n",
    "    multi_class=\"ovr\",\n",
    "    max_iter=2000000,\n",
    "    random_state=42,\n",
    "    n_jobs=24,\n",
    "    #     penalty=\"elasticnet\",\n",
    "    cv=def_cv,\n",
    "    scoring=\"f1_macro\",\n",
    "    solver=\"lbfgs\",\n",
    "    Cs=100,\n",
    "    #     l1_ratios=np.linspace(0, 1, endpoint=False, num=100),\n",
    ")\n",
    "from sklearnex import unpatch_sklearn\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "discrete = nominal + discrete_ordinal + discrete_binary\n",
    "X_master = pd.concat(\n",
    "    [raw_data.loc[:, raw_data_eval.columns], raw_data_eval], ignore_index=True, axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26012c89-58e2-4eb2-887e-a2c1c4146b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214e628-0ff9-440a-8f9a-12e63c2ebc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ALPHA = 1.0e-10\n",
    "clf_1 = CategoricalNB(alpha=ALPHA, fit_prior=True, min_categories=2)\n",
    "clf_2 = ComplementNB(alpha=ALPHA, fit_prior=True, norm=False)\n",
    "clf_3 = BernoulliNB(binarize=False, alpha=ALPHA, fit_prior=True)\n",
    "clf_4 = MultinomialNB(alpha=ALPHA, fit_prior=True)\n",
    "# clf1_ = make_pipeline(VarianceThreshold(0.0001),clf_1)\n",
    "# clf2_ = make_pipeline(VarianceThreshold(0.0001),clf_2)\n",
    "# clf3_  = make_pipeline(VarianceThreshold(0.0001),clf_3)\n",
    "# clf4_  = make_pipeline(VarianceThreshold(0.0001),clf_4)\n",
    "\n",
    "\n",
    "clfs = []\n",
    "for clf in [clf_1, clf_2, clf_3, clf_4]:\n",
    "    clfs.append(OneVsOneClassifier(clf, n_jobs=-1))\n",
    "# clfs = [clf1_,clf2_,clf3_,clf4_]\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(sparse=False), nominal + discrete_ordinal),\n",
    "    (\"passthrough\", discrete_binary),\n",
    "    sparse_threshold=0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "ct.fit(X_raw)\n",
    "\n",
    "X, y = (\n",
    "    pd.DataFrame(ct.transform(X_raw), columns=cleanup_feature_names(ct)),\n",
    "    raw_data.target,\n",
    ")\n",
    "\n",
    "other = X_raw.index.difference(fin_idx)\n",
    "\n",
    "X_train, X_test, y_train, y_test = gen_train_test(\n",
    "    X.loc[other, :], y.loc[other], test_size=0.3\n",
    ")\n",
    "# X.\n",
    "# clfs = [clf_1, clf_2, clf_3, clf_4]\n",
    "stc = StackingClassifier(\n",
    "    estimators=[(f\"clf_{i}\", clfs[i]) for i in range(4)],\n",
    "    final_estimator=LogisticRegressionCV(**lgr_params),\n",
    "    n_jobs=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a0650-9591-44a8-a537-378660296bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "with parallel_backend(\"loky\"):\n",
    "    for clf in stc.estimators_:\n",
    "        #     sc = cross_validate(clf,X,y,cv=RepeatedStratifiedKFold(),n_jobs=-1,scoring='f1_macro',)\n",
    "        #     res.append(sc)\n",
    "        #     clf = clf_[-1]\n",
    "        clf.partial_fit(X.loc[fin_idx, :], y.loc[fin_idx], classes=[0, 1, 2])\n",
    "        #     clf.partial_fit(X[fin_idx,:],y.loc[fin_idx],classes=[0,1,2])\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=20)\n",
    "\n",
    "        for train_index, test_index in cv.split(X_train, y_train):\n",
    "            X_train_, X_test_ = X.loc[train_index, :], X.loc[test_index, :]\n",
    "            y_train_, y_test_ = y.loc[train_index], y.loc[test_index]\n",
    "            #         clf.partial_fit(X_test_,y_test_)\n",
    "            clf.partial_fit(X_test_, y_test_, classes=[0, 1, 2])\n",
    "            #         print(X_train.shape)\n",
    "\n",
    "            clf.partial_fit(X_train_, y_train_, classes=[0, 1, 2])\n",
    "    #         clf.partial_fit(X_train_,y_train_)\n",
    "y_preds = [clf.predict(X_test) for clf in clfs]\n",
    "y_pred_base = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred_base))\n",
    "for y_pred in y_preds:\n",
    "    print(classification_report(y_test, y_pred))\n",
    "clfs = [clf_1, clf_2, clf_3, clf_4]\n",
    "stc = StackingClassifier(\n",
    "    estimators=[(f\"clf_{i}\", clfs[i]) for i in range(4)],\n",
    "    final_estimator=LogisticRegressionCV(**lgr_params),\n",
    "    n_jobs=24,\n",
    ")\n",
    "stc\n",
    "X_transformed = stc.transform(X_test)\n",
    "stc.final_estimator_.fit(X_test, y_test)\n",
    "# y_pred = stc.fit(X_train,y_train).predict(X_test)\n",
    "y_pred = stc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ca4cf-789b-42db-b295-6c4f693d980b",
   "metadata": {},
   "source": [
    "```text\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.76      0.60      0.67       345\n",
    "         1.0       0.79      0.78      0.78       531\n",
    "         2.0       0.43      0.59      0.50       199\n",
    "\n",
    "    accuracy                           0.69      1075\n",
    "   macro avg       0.66      0.66      0.65      1075\n",
    "weighted avg       0.71      0.69      0.69      1075\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.77      0.68      0.72       345\n",
    "         1.0       0.84      0.79      0.82       531\n",
    "         2.0       0.48      0.65      0.55       199\n",
    "\n",
    "    accuracy                           0.73      1075\n",
    "   macro avg       0.70      0.71      0.70      1075\n",
    "weighted avg       0.75      0.73      0.74      1075\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.79      0.66      0.72       345\n",
    "         1.0       0.85      0.78      0.81       531\n",
    "         2.0       0.45      0.67      0.54       199\n",
    "\n",
    "    accuracy                           0.72      1075\n",
    "   macro avg       0.69      0.70      0.69      1075\n",
    "weighted avg       0.75      0.72      0.73      1075\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.77      0.68      0.72       345\n",
    "         1.0       0.84      0.79      0.82       531\n",
    "         2.0       0.48      0.65      0.55       199\n",
    "\n",
    "    accuracy                           0.73      1075\n",
    "   macro avg       0.70      0.71      0.70      1075\n",
    "weighted avg       0.75      0.73      0.74      1075\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.78      0.68      0.73       345\n",
    "         1.0       0.84      0.81      0.82       531\n",
    "         2.0       0.48      0.64      0.55       199\n",
    "\n",
    "    accuracy                           0.73      1075\n",
    "   macro avg       0.70      0.71      0.70      1075\n",
    "weighted avg       0.75      0.73      0.74      1075\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c7930f-d35b-491f-8504-72b935321feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ne = [\n",
    "    \"nominal__v_12\",\n",
    "    \"nominal__v_18\",\n",
    "    \"nominal__v_20\",\n",
    "    \"nominal__v_25\",\n",
    "    \"nominal__v_3\",\n",
    "    \"nominal__v_32\",\n",
    "    \"nominal__v_4\",\n",
    "]\n",
    "df = X_master[Ne]\n",
    "train = raw_data\n",
    "evale = raw_data_eval\n",
    "all_infreq_idx_train = None\n",
    "all_infreq_idx_eval = None\n",
    "perf = {}\n",
    "N_dims = X_master[nominal].nunique().sum()\n",
    "for dims in range(2, 30):\n",
    "    dim_reduction = 0\n",
    "\n",
    "    for c in Ne:\n",
    "        #         print(\":\"*80)\n",
    "        #     pp()\n",
    "        vc = df[c].value_counts().sort_values(ascending=False)\n",
    "        vc_ = vc[vc < dims]\n",
    "        t_samples = vc_.sum()\n",
    "        dim_reduction += vc_.shape[0]\n",
    "        #         print(c,vc_.shape[0])\n",
    "        vc_ = vc_.to_dict()\n",
    "        v_t = train[c].value_counts().sort_values(ascending=False).to_dict()\n",
    "        v_e = evale[c].value_counts().sort_values(ascending=False).to_dict()\n",
    "        N_train = 0\n",
    "        N_eval = 0\n",
    "        for val in vc_:\n",
    "            if val in v_t:\n",
    "                N_train += v_t[val]\n",
    "            if val in v_e:\n",
    "                N_eval += v_e[val]\n",
    "        #         print(\"Training Samples : \", N_train)\n",
    "        #         print(\"Eval Samples : \", N_eval)\n",
    "        #         print(\"Total Samples: \", t_samples)\n",
    "\n",
    "        for val in vc_:\n",
    "            if type(all_infreq_idx_train) == pd.core.indexes.numeric.Int64Index:\n",
    "                all_infreq_idx_train = all_infreq_idx_train.union(\n",
    "                    raw_data[raw_data[c] == val].index\n",
    "                )\n",
    "            else:\n",
    "                all_infreq_idx_train = raw_data[raw_data[c] == val].index\n",
    "            if type(all_infreq_idx_eval) == pd.core.indexes.numeric.Int64Index:\n",
    "                all_infreq_idx_eval = all_infreq_idx_eval.union(\n",
    "                    raw_data_eval[raw_data[c] == val].index\n",
    "                )\n",
    "            else:\n",
    "                all_infreq_idx_eval = raw_data_eval[raw_data[c] == val].index\n",
    "    #     print(\":\"*80)\n",
    "    #     print(\":\"*80)\n",
    "    try:\n",
    "        v1 = (len(all_infreq_idx_train) / 3796) * 100\n",
    "    except TypeError as e:\n",
    "        v1 = 0\n",
    "\n",
    "    try:\n",
    "        v2 = (len(all_infreq_idx_eval) / 1628) * 100\n",
    "    except TypeError as e:\n",
    "        v2 = 0\n",
    "\n",
    "    try:\n",
    "        v3 = (dim_reduction / N_dims) * 100\n",
    "    except TypeError as e:\n",
    "        v3 = 0\n",
    "\n",
    "    print(\"Total Training Samples:\", v1, \"%\")\n",
    "    print(\"Total Eval Samples:\", v2, \"%\")\n",
    "    print(\"Total Dim Reduction:\", v3, \"%\")\n",
    "\n",
    "    perf[dims] = {\n",
    "        \"Total Training Samples\": v1,\n",
    "        \"Total Eval Samples\": v2,\n",
    "        \"Total Dim Reduction\": v3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb126b8-df39-4b65-9434-413835a0ad74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame(perf).transpose()\n",
    "_ = perf_df.plot(xticks=np.arange(2, 30), figsize=(20, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead86910-9eeb-429e-b3dd-ab172c8dd3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perf_df.sort_values(by=['Total Dim Reduction'],ascending=False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44af49f6-6cca-4dcf-b642-010e5b98e3c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-11T14:44:32.876905Z",
     "iopub.status.busy": "2022-09-11T14:44:32.876401Z",
     "iopub.status.idle": "2022-09-11T14:44:32.916742Z",
     "shell.execute_reply": "2022-09-11T14:44:32.915998Z",
     "shell.execute_reply.started": "2022-09-11T14:44:32.876857Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2, 13, 22, 20, 13, 30, 25, 26, 14, 19,\n",
       "       25, 43, 24, 28, 21])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe.nunique().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd2a7976-0d00-4a8d-8bd5-2f615812c9c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-11T14:52:32.556484Z",
     "iopub.status.busy": "2022-09-11T14:52:32.556072Z",
     "iopub.status.idle": "2022-09-11T14:58:47.809933Z",
     "shell.execute_reply": "2022-09-11T14:58:47.809382Z",
     "shell.execute_reply.started": "2022-09-11T14:52:32.556443Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6628778516299143\n",
      "0.6628778516299143\n",
      "0.6639604351225585\n",
      "0.6628778516299143\n",
      "0.6628778516299143\n",
      "0.6628778516299143\n",
      "0.6628778516299143\n",
      "0.6628778516299143\n",
      "0.6648675280388835\n",
      "0.6627297254206158\n",
      "0.6585990515396233\n",
      "0.6585990515396233\n",
      "0.656620964321459\n",
      "0.6545149281256452\n",
      "0.6545050457435962\n",
      "0.6535828389453561\n",
      "0.6511245447008182\n",
      "0.6525273112608986\n",
      "0.6511245447008182\n",
      "0.6514534794778675\n",
      "0.6516168249553494\n",
      "0.6502618843416483\n",
      "0.6487293452487045\n",
      "0.6486933419780622\n",
      "0.6470045106408743\n",
      "0.6459517127464773\n",
      "0.6479642697711687\n",
      "0.6662392446428608\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def train_nb_clf(clf, X, y):\n",
    "    X_train, X_test, y_train, y_test = gen_train_test(X, y, test_size=0.2)\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=36851234)\n",
    "    progd = []\n",
    "    for train_index, test_index in rskf.split(X_train, y_train):\n",
    "        #         print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train_, X_test_ = X.loc[train_index, :], X.loc[test_index, :]\n",
    "        y_train_, y_test_ = y.loc[train_index], y.loc[test_index]\n",
    "        y_pred_ = clf.partial_fit(X_train_, y_train_, classes=[0, 1, 2])\n",
    "        y_pred_ = clf.partial_fit(X_test_, y_test_, classes=[0, 1, 2])\n",
    "    #         prog = f1_score(y_test,clf.predict(X_test),average='macro')\n",
    "    #         progd.append(prog)\n",
    "    clf.partial_fit(X_train, y_train)\n",
    "    prog = f1_score(y_test, clf.predict(X_test), average=\"macro\")\n",
    "    progd.append(prog)\n",
    "    print(np.array(progd).mean())\n",
    "    #     fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "    #     _  = pd.Series(progd).plot(ax=ax,title=str(X.nunique().sum()))\n",
    "    return progd\n",
    "\n",
    "\n",
    "vc_all = {c: X_master[c].value_counts() for c in nominal}\n",
    "n_neighbours = (\n",
    "    list(np.arange(2, 10)) + list(np.arange(10, 50, 5)) + list(np.arange(50, 500, 25))\n",
    ")\n",
    "for c in nominal + discrete_ordinal + discrete_binary:\n",
    "    raw_data[c] = raw_data[c].astype(np.uint16)\n",
    "y = raw_data.target\n",
    "ohe = make_column_transformer(\n",
    "    (OneHotEncoder(sparse=False, dtype=np.int64), nominal),\n",
    "    remainder=\"passthrough\",\n",
    "    sparse_threshold=0,\n",
    ")\n",
    "chi2_ohe = make_column_transformer(\n",
    "    (OneHotEncoder(sparse=False, dtype=np.int64), nominal),\n",
    "    (\"passthrough\", discrete_binary + discrete_ordinal),\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0,\n",
    ")\n",
    "# chi2_ohe = make_column_transformer(('passthrough',nominal),remainder='drop',sparse_threshold=0)\n",
    "def discrete_features_list(df):\n",
    "    d_mask = []\n",
    "    for c in df.columns:\n",
    "        if c in discrete_ordinal + discrete_binary or \"nominal\" in c:\n",
    "            d_mask.append(True)\n",
    "        else:\n",
    "            d_mask.append(False)\n",
    "    return np.array(d_mask)\n",
    "\n",
    "\n",
    "master_chi_X = {}\n",
    "master_chi_R = {}\n",
    "\n",
    "\n",
    "def remove_infreq(row, CUT):\n",
    "    for c in nominal:\n",
    "        if vc_all[c][row[c]] <= CUT:\n",
    "            row[c] = max(list(vc_all[c].keys())) + 1\n",
    "    return row\n",
    "\n",
    "\n",
    "clf = CategoricalNB(\n",
    "    alpha=1e-10, min_categories=X_ohe.nunique().to_numpy(), fit_prior=True\n",
    ")\n",
    "dif_trained_clfs = []\n",
    "with parallel_backend(\"threading\", n_jobs=24):\n",
    "    for cut_val in range(3, 30):\n",
    "        clf = OneVsRestClassifier(\n",
    "            CategoricalNB(\n",
    "                alpha=1e-10, min_categories=X_ohe.nunique().to_numpy(), fit_prior=False\n",
    "            )\n",
    "        )\n",
    "        X_ = raw_data[raw_data_eval.columns].copy()\n",
    "        X_ = X_.apply(remove_infreq, axis=1, CUT=cut_val)\n",
    "        X_ohe = chi2_ohe.fit_transform(X_)\n",
    "        X_ohe = pd.DataFrame(X_ohe, columns=cleanup_feature_names(chi2_ohe)).astype(\n",
    "            \"int\"\n",
    "        )\n",
    "        d_f_x = discrete_features_list(X_ohe)\n",
    "        clf = OneVsRestClassifier(\n",
    "            CategoricalNB(\n",
    "                alpha=1e-10, min_categories=X_ohe.nunique().to_numpy(), fit_prior=False\n",
    "            )\n",
    "        )\n",
    "        fit_clf = train_nb_clf(clf, X_ohe, y)\n",
    "        dif_trained_clfs.append(fit_clf)\n",
    "\n",
    "r_ohe = chi2_ohe.fit_transform(raw_data[raw_data_eval.columns])\n",
    "r_ohe = pd.DataFrame(r_ohe, columns=cleanup_feature_names(chi2_ohe))\n",
    "d_f_r = discrete_features_list(r_ohe)\n",
    "#     mic_R = {}\n",
    "#     for i in tqdm(n_neighbours):\n",
    "#         mic_R[i] = chi2(r_ohe,y)\n",
    "#     for cut_val in trange(3,30):\n",
    "clf = OneVsRestClassifier(\n",
    "    CategoricalNB(\n",
    "        alpha=1e-10, min_categories=r_ohe.nunique().to_numpy(), fit_prior=False\n",
    "    )\n",
    ")\n",
    "master_clf_R = train_nb_clf(clf, r_ohe, y)\n",
    "#         master_chi_R[cut_val] = chi2(r_ohe,y)\n",
    "#         break\n",
    "\n",
    "#     break\n",
    "#                    X\n",
    "#                   /\n",
    "# CUT-->N_neighbours-\n",
    "#                   \\\n",
    "#                    R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b008b8b1-846d-413b-930a-407f6781ac59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-11T14:37:41.528189Z",
     "iopub.status.busy": "2022-09-11T14:37:41.527777Z",
     "iopub.status.idle": "2022-09-11T14:37:41.537220Z",
     "shell.execute_reply": "2022-09-11T14:37:41.536004Z",
     "shell.execute_reply.started": "2022-09-11T14:37:41.528146Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4533015163571735,\n",
       " 0.4799144562775736,\n",
       " 0.5479351847338002,\n",
       " 0.5268523200298126,\n",
       " 0.5459953999939327,\n",
       " 0.5152393744021359,\n",
       " 0.486821629172036,\n",
       " 0.5536721563951611,\n",
       " 0.5282478189628449,\n",
       " 0.5543883957504658,\n",
       " 0.5377248324217212,\n",
       " 0.5184996958093436,\n",
       " 0.5169879189316409,\n",
       " 0.5269572956730365,\n",
       " 0.5387495984181067,\n",
       " 0.5432321337329459,\n",
       " 0.5167735996790391,\n",
       " 0.5568086967331752,\n",
       " 0.5135989532166675,\n",
       " 0.5048815415012599,\n",
       " 0.5136193228015323,\n",
       " 0.5368060362064387,\n",
       " 0.4936750551607651,\n",
       " 0.5372978060659855,\n",
       " 0.564204306786504,\n",
       " 0.5457636500003606,\n",
       " 0.5163914475032275,\n",
       " 0.5290679326785201,\n",
       " 0.5341961657198085,\n",
       " 0.5270424638176714,\n",
       " 0.5098954164144816,\n",
       " 0.5292042866298704,\n",
       " 0.5386671721349141,\n",
       " 0.5308203765638465,\n",
       " 0.5386962346165381,\n",
       " 0.50839042427192,\n",
       " 0.5388602881657762,\n",
       " 0.5506368585169917,\n",
       " 0.5194249503552978,\n",
       " 0.5376554751940547,\n",
       " 0.5183420880969547,\n",
       " 0.5449995485273238,\n",
       " 0.5477220448381227,\n",
       " 0.5384791010015327,\n",
       " 0.5051784404588533,\n",
       " 0.5159399397726356,\n",
       " 0.5550521148898432,\n",
       " 0.5358702116381595,\n",
       " 0.507419399474194,\n",
       " 0.5330307465958845,\n",
       " 0.5018594168778573]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif_trained_clfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2359dd8f-2c0c-4d52-a4a4-284ea68600e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-11T13:56:22.272804Z",
     "iopub.status.busy": "2022-09-11T13:56:22.272263Z",
     "iopub.status.idle": "2022-09-11T13:56:22.280481Z",
     "shell.execute_reply": "2022-09-11T13:56:22.279900Z",
     "shell.execute_reply.started": "2022-09-11T13:56:22.272748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_nb_clf(clf, X, y):\n",
    "    X_train, X_test, y_train, y_test = gen_train_test(X, y, test_size=0.2)\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=20, n_repeats=20, random_state=36851234)\n",
    "    progd = []\n",
    "    for train_index, test_index in rskf.split(X_train, y_train):\n",
    "        #         print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train_, X_test_ = X[train_index], X[test_index]\n",
    "        y_train_, y_test_ = y[train_index], y[test_index]\n",
    "        y_pred_ = clf.partial_fit(X_train_, y_train_)\n",
    "        prog = f1_score(y_test_, clf.predict(X_test_), average=\"macro\")\n",
    "        progd.append(prog)\n",
    "    prog = f1_score(y_test, clf.predict(X_test), average=\"macro\")\n",
    "    progd.append(prog)\n",
    "    _ = pd.Series(progd).plot()\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf8ad2-c23e-4a49-9685-4bfffb3cd73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_ohe.shape)\n",
    "X_ohe.var()\n",
    "r_ohe.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e6e2c-54e1-45ab-8522-683a97f0b289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "master_chi_X\n",
    "chi_sig = []\n",
    "chi_sig2 = []\n",
    "for thr in master_chi_X:\n",
    "    chi_val, p = master_chi_X[thr]\n",
    "    chi_sig.append(len(p[p > 0.05]))\n",
    "for thr in master_chi_R:\n",
    "    chi_val, p = master_chi_R[thr]\n",
    "    chi_sig2.append(len(p[p > 0.05]))\n",
    "# _ = plt.plot(chi_sig)\n",
    "# _ = plt.plot(chi_sig2)\n",
    "chi_sig = np.array(chi_sig)\n",
    "chi_sig2 = np.array(chi_sig2)\n",
    "# print(chi_sig)\n",
    "print(list(zip(list(np.arange(3, 30)), chi_sig - chi_sig2)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9f69a-6330-4673-b1fd-8418c5b94c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump([master_X, master_R], \"../data/MIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901f753-bc1a-42a4-93ac-e04b502cb928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mdf_X = pd.DataFrame(master_X)\n",
    "l, b = mdf_X.shape[0], mdf_X.shape[1]\n",
    "mdf_X_var = mdf_X.copy()\n",
    "mdf_X_std = mdf_X.copy()\n",
    "for i in range(l):\n",
    "    for j in range(b):\n",
    "        mdf_X_var.iloc[i, j] = mdf_X_var.iloc[i, j].var()\n",
    "        mdf_X_std.iloc[i, j] = mdf_X_std.iloc[i, j].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3e1c4-9865-4b4a-9957-a3e4d152adea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mdf_X_var * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1877b2-95d3-42fe-b21d-a4aa30439e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mdf_X * 1000\n",
    "e = np.empty((253,))\n",
    "X_stack_N = mdf_X.loc[:, 3].to_numpy()\n",
    "for s_ in X_stack_N:\n",
    "    #     print(len(s_))\n",
    "    e = np.c_[e, s_]\n",
    "#     print(s_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b35d60-9864-4005-afcb-334cbf6cbced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_stack_N = mdf_X.loc[:, 12].to_numpy()\n",
    "for s_ in X_stack_N:\n",
    "    #     e = np.c_[e,s_]\n",
    "    print(s_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab61582-bddf-4e10-8700-ad54bfc66d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_mic = np.zeros((27,35))\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527a8df-7608-4e4f-ba96-48bd2f1d3153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t in master:\n",
    "    for n in master[t]:\n",
    "        n[\"X\"].mean() - n[\"R\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca93135-7527-420a-a279-87d13f944254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
