{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2aba7b-b4e8-45f3-9d62-3d3823e0b750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    Binarizer,\n",
    "    StandardScaler,\n",
    "    LabelBinarizer,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# from xgboost import XGBRFClassifier, XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# sns.set()\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    Product,\n",
    "    RBF,\n",
    "    CompoundKernel,\n",
    "    Exponentiation,\n",
    "    Matern,\n",
    "    Sum,\n",
    ")\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    MinMaxScaler,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "import warnings\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import plotly.express as px\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    # StratifiedGroupKFold,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "import sigopt\n",
    "\n",
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    CategoricalNB,\n",
    "    MultinomialNB,\n",
    "    ComplementNB,\n",
    "    GaussianNB,\n",
    ")\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "nb_est = [CategoricalNB(), MultinomialNB(), ComplementNB(), GaussianNB()]\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_selection import (\n",
    "    mutual_info_classif,\n",
    "    SelectKBest,\n",
    "    f_classif,\n",
    "    chi2,\n",
    "    RFE,\n",
    "    SelectFdr,\n",
    "    SelectFpr,\n",
    "    SelectFwe,\n",
    "    SelectPercentile,\n",
    ")\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# from autosklearn.automl import AutoMLClassifier\n",
    "import sklearn.metrics\n",
    "\n",
    "dtype_info = {\n",
    "    \"v_1\": \"Binary\",\n",
    "    \"v_26\": \"Binary\",\n",
    "    \"v_11\": \"Binary\",\n",
    "    \"v_14\": \"Binary\",\n",
    "    \"v_30\": \"Binary\",\n",
    "    \"v_28\": \"Binary\",\n",
    "    \"v_9\": \"Binary\",\n",
    "    \"v_27\": \"Binary\",\n",
    "    \"v_32\": \"Nominal\",\n",
    "    \"v_4\": \"Nominal\",\n",
    "    \"v_3\": \"Nominal\",\n",
    "    \"v_20\": \"Nominal\",\n",
    "    \"v_21\": \"Nominal\",\n",
    "    \"v_18\": \"Nominal\",\n",
    "    \"v_25\": \"Nominal\",\n",
    "    \"v_12\": \"Nominal\",\n",
    "    \"v_31\": \"Ordinal\",\n",
    "    \"v_15\": \"Ordinal\",\n",
    "    \"v_19\": \"Ordinal\",\n",
    "    \"v_13\": \"Ordinal\",\n",
    "    \"v_33\": \"Ordinal\",\n",
    "    \"v_17\": \"Ordinal\",\n",
    "    \"v_29\": \"Ordinal\",\n",
    "    \"v_23\": \"Ordinal\",\n",
    "    \"v_6\": \"Ordinal\",\n",
    "    \"v_24\": \"Ordinal\",\n",
    "    \"v_10\": \"Ordinal\",\n",
    "    \"v_5\": \"Ordinal\",\n",
    "    \"v_22\": \"Ordinal\",\n",
    "    \"v_0\": \"Ordinal\",\n",
    "    \"v_16\": \"Ratio\",\n",
    "    \"v_2\": \"Ratio\",\n",
    "    \"v_8\": \"Ratio\",\n",
    "    \"v_7\": \"Ratio\",\n",
    "    \"v_39\": \"Ratio\",\n",
    "    \"v_37\": \"Ratio\",\n",
    "    \"v_38\": \"Ratio\",\n",
    "    \"v_34\": \"Ratio\",\n",
    "    \"v_40\": \"Ratio\",\n",
    "    \"v_36\": \"Ratio\",\n",
    "    \"v_35\": \"Ratio\",\n",
    "}\n",
    "# data = pd.read_csv(\n",
    "#     \"../data/train.csv\",\n",
    "#     index_col=0,\n",
    "# )\n",
    "data__ = pd.read_parquet(\"../data/data_with_ridit.hdfs\", engine=\"fastparquet\")\n",
    "prediction_data = pd.read_parquet(\"../data/test.parquet\", engine=\"fastparquet\")\n",
    "data = pd.read_parquet(\"../data/train.parquet\", engine=\"fastparquet\")\n",
    "ordinal = [i for i in dtype_info if dtype_info[i] == \"Ordinal\"]\n",
    "nominal = [i for i in dtype_info if dtype_info[i] == \"Nominal\"]\n",
    "binary = [i for i in dtype_info if dtype_info[i] == \"Binary\"]\n",
    "ratio = [i for i in dtype_info if dtype_info[i] == \"Ratio\"]\n",
    "\n",
    "\n",
    "final_data = pd.read_parquet(\"../data/final_data.parquet\", engine=\"fastparquet\")\n",
    "final_pred_data = pd.read_parquet(\n",
    "    \"../data/final_pred_data.parquet\", engine=\"fastparquet\"\n",
    ")\n",
    "\n",
    "\n",
    "def categorise_data(data):\n",
    "    ordinal_data = data.loc[:, ordinal]\n",
    "    nominal_data = data.loc[:, nominal]\n",
    "    binary_data = data.loc[:, binary]\n",
    "    ratio_data = data.loc[:, ratio]\n",
    "    return ordinal_data, nominal_data, binary_data, ratio_data\n",
    "\n",
    "\n",
    "ordinal_data, nominal_data, binary_data, ratio_data = categorise_data(data)\n",
    "\n",
    "\n",
    "def gen_train_test(data, p):\n",
    "    Y = data.label\n",
    "    X_2 = Y_2 = Y[Y == 2].index\n",
    "    X_0 = Y_0 = Y[Y == 0].index\n",
    "    X_1 = Y_1 = Y[Y == 1].index\n",
    "    train_size = int(p * Y_2.shape[0])\n",
    "    test_size = int((1 - p) * Y_2.shape[0])\n",
    "\n",
    "    train_idx_2 = np.random.choice(Y_2, (train_size,))\n",
    "    train_idx_1 = np.random.choice(Y_1, (train_size,))\n",
    "    train_idx_0 = np.random.choice(Y_0, (train_size,))\n",
    "    train_idx = np.r_[train_idx_0, train_idx_1, train_idx_2]\n",
    "    # train_idx.shape\n",
    "\n",
    "    test_idx_2 = np.random.choice(np.setdiff1d(Y_2, train_idx_2), (test_size,))\n",
    "    test_idx_1 = np.random.choice(np.setdiff1d(Y_1, train_idx_1), (test_size,))\n",
    "    test_idx_0 = np.random.choice(np.setdiff1d(Y_0, train_idx_0), (test_size,))\n",
    "    test_idx = np.r_[test_idx_0, test_idx_1, test_idx_2]\n",
    "    # test_idx.shape\n",
    "    return train_idx, test_idx\n",
    "\n",
    "\n",
    "def best_n_features(n, X_train, y_train):\n",
    "    ohe = OneHotEncoder(\n",
    "        min_frequency=0.00001, handle_unknown=\"infrequent_if_exist\", sparse=False\n",
    "    )\n",
    "    X_train_t = ohe.fit_transform(X_train)\n",
    "    mic = mutual_info_classif(X_train_t, y_train, discrete_features=True)\n",
    "\n",
    "    return ohe.get_feature_names_out()[mic.argsort()[-n:]]\n",
    "\n",
    "\n",
    "# prediction_data = pd.read_pickle(\"../data/pred_data.pkl\")\n",
    "\n",
    "import os\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "\n",
    "# est_ = [(\"cnb\",CategoricalNB()),]\n",
    "\n",
    "os.environ[\"SIGOPT_PROJECT\"] = \"notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e4fb69b-ec40-4546-9e42-bb321a6fa534",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet('../data/train.parquet', engine='fastparquet', compression='brotli')\n",
    "prediction_data.to_parquet('../data/test.parquet', engine='fastparquet', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0174951c-f545-493b-afa7-4b2dab8e567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/mlop3n/PycharmProjects/sdpiit/notebooks/dask-worker-space/worker-05k_uhpp', purging\n"
     ]
    }
   ],
   "source": [
    "# final_data = data.copy()\n",
    "# final_pred_data = prediction_data.copy()\n",
    "\n",
    "\n",
    "def remove_nominal_junk(\n",
    "    hi_f,\n",
    "    final_data: pd.DataFrame = final_data,\n",
    "    data: pd.DataFrame = data,\n",
    "    final_pred_data: pd.DataFrame = final_pred_data,\n",
    "    prediction_data: pd.DataFrame = prediction_data,\n",
    "):\n",
    "    # hi_f = nominal\n",
    "    hi1 = data.loc[:, hi_f]\n",
    "    hi2 = prediction_data.loc[:, hi_f]\n",
    "\n",
    "    for c in hi_f:\n",
    "        print(c)\n",
    "        # print(hi_df[c].unique())\n",
    "        # print('-'*80)\n",
    "        print(\"Junk\")\n",
    "        junk = np.setdiff1d(hi1[c].unique(), hi2[c].unique())\n",
    "        print(junk)\n",
    "        # vc1 = hi1[c].value_counts().to_dict()\n",
    "        # total_junk = 0\n",
    "        for j in junk:\n",
    "            junk_idx = final_data[final_data[c] == j].index\n",
    "            final_data.loc[junk_idx, c] = 0\n",
    "        #     total_junk+= vc1[j]\n",
    "        # print(total_junk)\n",
    "\n",
    "        # print('Missing')\n",
    "        missing = np.setdiff1d(hi2[c].unique(), hi1[c].unique())\n",
    "        print(missing)\n",
    "        # vc2 = hi2[c].value_counts().to_dict()\n",
    "        # total_missing=0\n",
    "        for m in missing:\n",
    "            missing_idx = final_pred_data[final_pred_data[c] == m].index\n",
    "            final_pred_data.loc[missing_idx, c] = 0\n",
    "        # print(total_missing)\n",
    "        print(\"-\" * 80)\n",
    "    return final_data, final_pred_data\n",
    "\n",
    "\n",
    "def round_up_ordinal(\n",
    "    hi_f,\n",
    "    final_data: pd.DataFrame = final_data,\n",
    "    final_pred_data: pd.DataFrame = final_pred_data,\n",
    "):\n",
    "    final_data.loc[:, hi_f] = final_data.loc[:, hi_f].round(1)\n",
    "    final_pred_data.loc[:, hi_f] = final_pred_data.loc[:, hi_f].round(1)\n",
    "    return final_data, final_pred_data\n",
    "\n",
    "\n",
    "def register_category(\n",
    "    hi_f,\n",
    "    final_data: pd.DataFrame = final_data,\n",
    "    final_pred_data: pd.DataFrame = final_pred_data,\n",
    "):\n",
    "    final_data.loc[:, hi_f] = final_data.loc[:, hi_f].astype(\"category\")\n",
    "    final_pred_data.loc[:, hi_f] = final_pred_data.loc[:, hi_f].astype(\"category\")\n",
    "    return final_data, final_pred_data\n",
    "\n",
    "\n",
    "# final_data, final_pred_data = round_up_ordinal(ordinal)\n",
    "# final_data, final_pred_data = remove_nominal_junk(nominal)\n",
    "# final_data, final_pred_data = register_category(ordinal+nominal)\n",
    "# final_data.to_parquet('../data/final_data.parquet',engine='fastparquet',compression='brotli')\n",
    "# final_pred_data.to_parquet('../data/final_pred_data.parquet',engine='fastparquet',compr\n",
    "from distributed import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecc317d5-3852-4367-a02e-23e7f5339075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=0.001,\n",
      "              sparse=False), \n",
      "     v_32  v_4  v_3 v_20 v_21 v_18 v_25 v_12\n",
      "id                                          \n",
      "285     6   76   39    0    3    3   27   16\n",
      "2034    0  172   96  257   10  106  181   22\n",
      "2226   92   96  131  242    3  121  165   16\n",
      "3438  120   55   91  252   11   14  183   22\n",
      "1285  116   59   39  251    3  103  181   16\n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...\n",
      "2162    6   96   45    6    3   23    1   16\n",
      "2832    6  121   17   60    3   30    3   41\n",
      "2663  116  167   44  168    3  103  183   16\n",
      "2069    6  155   70  251    3  103  181   16\n",
      "1541   13  121    0  168    7   20    7   23\n",
      "\n",
      "[1656 rows x 8 columns], \n",
      "id\n",
      "285     0\n",
      "2034    0\n",
      "2226    0\n",
      "3438    0\n",
      "1285    0\n",
      "       ..\n",
      "2162    2\n",
      "2832    2\n",
      "2663    2\n",
      "2069    2\n",
      "1541    2\n",
      "Name: label, Length: 1656, dtype: int64, \n",
      "None, message_clsname='Pipeline', message=None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.44      0.46       151\n",
      "           1       0.44      0.41      0.42       146\n",
      "           2       0.31      0.38      0.34       114\n",
      "\n",
      "    accuracy                           0.41       411\n",
      "   macro avg       0.41      0.41      0.41       411\n",
      "weighted avg       0.42      0.41      0.41       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import Memory\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "ms = Memory(location=\"../data/tpot1/\")\n",
    "# kernel_rbf = Exponentiation(RBF(),30)\n",
    "# comp_kern = Sum(Matern(nu=1),kernel_rbf)\n",
    "\n",
    "estimators = [\n",
    "    # SVC(),\n",
    "    # NuSVC(),\n",
    "    # CategoricalNB(),\n",
    "    MultinomialNB(),\n",
    "    # ComplementNB(),\n",
    "    # GaussianNB(),\n",
    "    # AdaBoostClassifier(),\n",
    "    # PassiveAggressiveClassifier(),\n",
    "    # SGDClassifier(),\n",
    "    # MLPClassifier(),\n",
    "    # KNeighborsClassifier(),\n",
    "    # RadiusNeighborsClassifier(),\n",
    "    # ExtraTreesClassifier(),\n",
    "    # RandomForestClassifier(),\n",
    "    # DecisionTreeClassifier(),\n",
    "    # HistGradientBoostingClassifier(),\n",
    "    # GradientBoostingClassifier(),\n",
    "]\n",
    "est_ = []\n",
    "for e in estimators:\n",
    "    est_.append((e.__class__.__name__, e))\n",
    "\n",
    "\n",
    "train_idx, test_idx = gen_train_test(data, 0.8)\n",
    "X_train, y_train = (\n",
    "    final_data.loc[train_idx, nominal],\n",
    "    data[\"label\"].loc[train_idx],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    final_data.loc[test_idx, nominal],\n",
    "    data[\"label\"].loc[test_idx],\n",
    ")\n",
    "# model = StackingClassifier(\n",
    "#     estimators=est_,\n",
    "#     final_estimator=RandomForestClassifier(n_jobs=-1, max_features=None),\n",
    "#     cv=4,\n",
    "#     stack_method=\"auto\",\n",
    "#     n_jobs=-1,\n",
    "#     passthrough=True,\n",
    "#     verbose=1,\n",
    "# )\n",
    "ohe = OneHotEncoder(\n",
    "    min_frequency=0.001, handle_unknown=\"infrequent_if_exist\", sparse=False\n",
    ")\n",
    "# dtc = RandomForestClassifier(random_state=42,n_jobs=-1, criterion='entropy', max_features=None)\n",
    "model = GaussianProcessClassifier(\n",
    "    n_jobs=-1, n_restarts_optimizer=10, max_iter_predict=10000\n",
    ")\n",
    "fs = SelectKBest(score_func=mutual_info_classif, k=90)\n",
    "ovr = Pipeline(\n",
    "    [(\"OHE\", ohe), \n",
    "     (\"feature_selector\", fs), \n",
    "     (\"Model\", model)],\n",
    "    memory=ms,\n",
    ")\n",
    "with parallel_backend(\"threading\"):\n",
    "    ovr.fit(X_train, y_train)\n",
    "    print(classification_report(ovr.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c21c6-69de-4839-96d6-906d3fc70eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sigopt\n",
    "%sigopt config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b195e-218a-4d67-94af-d5436d03311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc__params = {\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"class_weight\": None,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": None,\n",
    "    \"max_features\": None,\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"min_impurity_split\": None,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"random_state\": None,\n",
    "    \"splitter\": \"best\",\n",
    "}\n",
    "\n",
    "# dtc.get_params()\n",
    "def evaluate_best_dtc(n_cv):\n",
    "    global data\n",
    "    dtc__params = {\n",
    "        \"ccp_alpha\": 0.0,\n",
    "        \"class_weight\": None,\n",
    "        \"criterion\": \"gini\",\n",
    "        \"max_depth\": None,\n",
    "        \"max_features\": None,\n",
    "        \"max_leaf_nodes\": None,\n",
    "        \"min_impurity_decrease\": 0.0,\n",
    "        \"min_impurity_split\": None,\n",
    "        \"min_samples_leaf\": np.random.randint(1, 5),\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_weight_fraction_leaf\": 0.0,\n",
    "        \"random_state\": 42,\n",
    "        \"splitter\": \"best\",\n",
    "    }\n",
    "    sigopt.log_dataset(\"Ordinal_Data\")\n",
    "    sigopt.log_model(DecisionTreeClassifier().__class__.__name__)\n",
    "    sigopt.log_metadata(key=\"Features\", value=ordinal)\n",
    "\n",
    "    train_idx, test_idx = gen_train_test(data, 1.0)\n",
    "    # X_train, y_train = ordinal_data.loc[train_idx, :], pd.get_dummies(data['label'].loc[train_idx])\n",
    "    X_train, y_train = ordinal_data.loc[train_idx, :], data[\"label\"].loc[train_idx]\n",
    "    for k, v in dtc__params.items():\n",
    "        sigopt.params.setdefault(k, v)\n",
    "    # clf = OneVsRestClassifier(model, n_jobs=-1)\n",
    "    with parallel_backend(\"threading\", n_jobs=-1):\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_features=14,\n",
    "            min_samples_leaf=dtc__params[\"min_samples_leaf\"],\n",
    "            min_impurity_decrease=sigopt.params.min_impurity_decrease,\n",
    "            random_state=42,\n",
    "            ccp_alpha=sigopt.params.ccp_alpha,\n",
    "        )\n",
    "        cv_results = cross_validate(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            scoring=\"f1_macro\",\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1,\n",
    "            cv=n_cv,\n",
    "            return_estimator=True,\n",
    "        )\n",
    "        sigopt.params.min_samples_leaf = model.min_samples_leaf\n",
    "    # sigopt.params.ccp_alpha=0\n",
    "    # print(sigopt.params)\n",
    "    sigopt.log_metric(name=\"f1_macro\", value=cv_results[\"test_score\"].mean())\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c40f3-1d2e-4c4f-8bf6-d9196f02f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%experiment\n",
    "{\n",
    "    'name': 'DTC Optimization',\n",
    "    'metrics': [\n",
    "        {\n",
    "            'name': 'f1_macro',\n",
    "            'strategy': 'optimize',\n",
    "            'objective': 'maximize',\n",
    "        }\n",
    "    ],\n",
    "    'parameters': [\n",
    "        {\n",
    "            'name': 'min_impurity_decrease',\n",
    "            'type': 'double',\n",
    "            'bounds': {'min': 0.0, 'max': 1.0}\n",
    "        }\n",
    "\n",
    "    ],\n",
    "    'type':'offline',\n",
    "    'budget': 10\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c650483-e91f-4159-b8e1-5ca7b53c5eaf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%optimize \n",
    "evaluate_best_dtc(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405a38b-7b89-40fb-b1e0-cabfcc0a9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = nom_dum.loc[train_idx,:], data['label'].loc[train_idx]\n",
    "# X_train, y_train = nominal_data.loc[train_idx,:], data['label'].loc[train_idx]\n",
    "# X_train, y_train = nom_dum.iloc[train_idx,imp_nom], data['label'].loc[train_idx]\n",
    "# cv_results = cross_validate(dtc, X_train, y_train, scoring='f1_macro', return_train_score=True, n_jobs=-1, cv=10, return_estimator=True, )\n",
    "# cv_results\n",
    "train_idx, test_idx = gen_train_test(data, 0.75)\n",
    "X_train, y_train = (\n",
    "    nominal_data.loc[train_idx, :].astype(\"category\"),\n",
    "    data[\"label\"].loc[train_idx],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    nominal_data.loc[test_idx, :].astype(\"category\"),\n",
    "    data[\"label\"].loc[test_idx],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d561de-5b2f-47a8-9560-9c92eb65d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qt_trial():\n",
    "    qt = QuantileTransformer(\n",
    "        n_quantiles=200, output_distribution=\"normal\", random_state=42\n",
    "    )\n",
    "    train_idx, test_idx = gen_train_test(data, 1.0)\n",
    "    X_train, y_train = (\n",
    "        ordinal_data.loc[\n",
    "            train_idx, [\"v_10\", \"v_17\", \"v_5\", \"v_29\", \"v_19\", \"v_22\", \"v_6\"]\n",
    "        ],\n",
    "        data[\"label\"].loc[train_idx],\n",
    "    )\n",
    "    for c in X_train:\n",
    "        med = X_train[c].median()\n",
    "        X_train[c] = (X_train[c]) / med\n",
    "    with parallel_backend(\"threading\", n_jobs=-1):\n",
    "        model = DecisionTreeClassifier(\n",
    "            criterion=\"entropy\",\n",
    "            # max_features='sqrt',\n",
    "            # learning_rate=0.\n",
    "            # n_jobs=-1,\n",
    "            # min_samples_leaf=1,\n",
    "            random_state=42,\n",
    "        )\n",
    "        model_wf = make_pipeline(qt, model)\n",
    "        cv_results = cross_validate(\n",
    "            model_wf,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            scoring=\"f1_macro\",\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1,\n",
    "            cv=3,\n",
    "            return_estimator=True,\n",
    "        )\n",
    "    cv_results[\"test_score\"].mean(), cv_results[\"train_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb61bc8-db87-4ec5-b93e-4c27aa35dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data = data.loc[:, nominal + ordinal].astype(\"category\")\n",
    "pre_category_data = prediction_data.loc[:, nominal + ordinal].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b277a1-074a-49bc-bad4-d37221cc9ef7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = pre_category_data.shape[0]\n",
    "\n",
    "for i in [0.1, 0.25, 0.5, 0.75, 0.80]:\n",
    "    s = f'pfig.add_hline(y={i*N}, line_dash=\"dot\", line_width=1,line_color=\"red\",annotation_text=\"{i*100}%\", annotation_position=\"bottom right\",annotation_font_size=11,annotation_font_color=\"black\")'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7a5d4-3f96-4d45-9419-99f4f34cbd28",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = pre_category_data.shape[0]\n",
    "# fig = plt.axhline(y = 0.5*N, color = 'r', linestyle = '--', label = \"50%\")\n",
    "# fig = plt.axhline(y = 0.80*N, color = 'g', linestyle = '--', label = \"80%\")\n",
    "# fig = plt.axhline(y = 0.25*N, color = 'y', linestyle = '--', label = \"25%\")\n",
    "# fig = plt.axhline(y = 0.15*N, color = 'black', linestyle = '--', label = \"15%\")\n",
    "\n",
    "# fig = plt.legend()\n",
    "pfig = (\n",
    "    pre_category_data.describe()\n",
    "    .loc[\"freq\", :]\n",
    "    .sort_values()\n",
    "    .plot(kind=\"bar\", title=\"Category Data Max_Freq from Test set\")\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=162.8,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"10.0%\",\n",
    "    annotation_position=\"bottom right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=407.0,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"25.0%\",\n",
    "    annotation_position=\"bottom left\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=814.0,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"50.0%\",\n",
    "    annotation_position=\"bottom right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=0.7 * N,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"70.0%\",\n",
    "    annotation_position=\"bottom left\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=1302.4,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"80.0%\",\n",
    "    annotation_position=\"bottom right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "\n",
    "pfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f650d-8407-407d-ad56-788559530c2b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = pre_category_data.shape[0]\n",
    "# fig = plt.axhline(y = 0.5*N, color = 'r', linestyle = '--', label = \"50%\")\n",
    "# fig = plt.axhline(y = 0.80*N, color = 'g', linestyle = '--', label = \"80%\")\n",
    "# fig = plt.axhline(y = 0.25*N, color = 'y', linestyle = '--', label = \"25%\")\n",
    "# fig = plt.axhline(y = 0.15*N, color = 'black', linestyle = '--', label = \"15%\")\n",
    "\n",
    "# fig = plt.legend()\n",
    "pfig = (\n",
    "    pre_category_data.round(2)\n",
    "    .describe()\n",
    "    .loc[\"freq\", :]\n",
    "    .sort_values()\n",
    "    .plot(kind=\"bar\", title=\"Category Data Max_Freq from Test set round 2\")\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=162.8,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"10.0%\",\n",
    "    annotation_position=\"bottom right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=407.0,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"25.0%\",\n",
    "    annotation_position=\"bottom left\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=814.0,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"50.0%\",\n",
    "    annotation_position=\"bottom right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=0.7 * N,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"70.0%\",\n",
    "    annotation_position=\"bottom left\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "pfig.add_hline(\n",
    "    y=1302.4,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"80.0%\",\n",
    "    annotation_position=\"bottom right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "\n",
    "pfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513be8ef-cb97-4743-b22b-bf67cf886a79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = category_data.shape[0]\n",
    "fig = (\n",
    "    category_data.round(1)\n",
    "    .describe()\n",
    "    .loc[\"freq\", :]\n",
    "    .sort_values()\n",
    "    .plot(kind=\"bar\", title=\"Category Data Max_Freq from Train set\")\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=379.6,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"10.0%\",\n",
    "    annotation_position=\"bottom right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=949.0,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"green\",\n",
    "    annotation_text=\"25.0%\",\n",
    "    annotation_position=\"bottom left\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=1898.0,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"50.0%\",\n",
    "    annotation_position=\"bottom right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=0.7 * N,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"70.0%\",\n",
    "    annotation_position=\"bottom left\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=3036.8,\n",
    "    line_dash=\"dot\",\n",
    "    line_width=1,\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"80.0%\",\n",
    "    annotation_position=\"top right\",\n",
    "    annotation_font_size=11,\n",
    "    annotation_font_color=\"black\",\n",
    ")\n",
    "\n",
    "\n",
    "# fig = plt.axhline(y = 0.60*N, color = 'r', linestyle = '--', label = \"50%\")\n",
    "# fig = plt.axhline(y = 0.75*N, color = 'g', linestyle = '--', label = \"75%\")\n",
    "# fig = plt.axhline(y = 0.25*N, color = 'y', linestyle = '--', label = \"25%\")\n",
    "# fig = plt.axhline(y = 0.15*N, color = 'black', linestyle = '--', label = \"15%\")\n",
    "# fig = plt.legend()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be8d16-8a4e-4a92-ab90-5377bb33f6e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = data.corrwith(data.label, method='kendall').sort_values().iloc[:-1].plot(kind='bar', figsize=(20,5))\n",
    "fig = (\n",
    "    data.round(1)\n",
    "    .corrwith(data.label, method=\"kendall\")\n",
    "    .sort_values()\n",
    "    .iloc[:-1]\n",
    "    .plot(kind=\"bar\", title=\"Kendall Correlation\")\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde44b0b-5713-45ab-8a39-18e2d948f90d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = data.corrwith(data.label, method='spearman').sort_values().iloc[:-1].plot(kind='bar', figsize=(20,5))\n",
    "fig = (\n",
    "    data.round(1)\n",
    "    .corrwith(data.label, method=\"spearman\")\n",
    "    .sort_values()\n",
    "    .iloc[:-1]\n",
    "    .plot(kind=\"bar\", title=\"Spearman Correlation\")\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af6d62-a265-4bea-872d-c008cf4834a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = data.corrwith(data.label, method='pearson').sort_values().iloc[:-1].plot(kind='bar', figsize=(20,5))\n",
    "fig = (\n",
    "    data.round(1)\n",
    "    .corrwith(data.label, method=\"pearson\")\n",
    "    .sort_values()\n",
    "    .iloc[:-1]\n",
    "    .plot(kind=\"bar\", title=\"Pearson Correlation\")\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23078306-20ca-400c-90e5-c16aabcfd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e421bde-cd0b-4076-b26a-2c0e1bddf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18548af2-17d7-4be7-8f1a-19c9286a1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_category_data.describe()\n",
    "total_category_data = pd.concat(\n",
    "    [category_data, pre_category_data],\n",
    "    axis=0,\n",
    ").astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446db6e-2909-463e-a6e6-109ad0f27c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorise_data\n",
    "tc_stat = total_category_data.describe()\n",
    "tc_stat.loc[\"freq\", :] = tc_stat.loc[\"freq\", :] / 5424\n",
    "tc_stat.loc[\"freq\", :].sort_values().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae339b-0d46-43d1-b3b4-6d63824d5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_junk_missing(\n",
    "    hi_f, data: pd.DataFrame = data, prediction_data: pd.DataFrame = prediction_data\n",
    "):\n",
    "    # hi_f = nominal\n",
    "    hi1 = data.loc[:, hi_f].round(1)\n",
    "    hi2 = prediction_data.loc[:, hi_f].round(1)\n",
    "\n",
    "    for c in hi_f:\n",
    "        print(c)\n",
    "        # print(hi_df[c].unique())\n",
    "        # print('-'*80)\n",
    "        print(\"Junk\")\n",
    "        junk = np.setdiff1d(hi1[c].unique(), hi2[c].unique())\n",
    "        print(np.setdiff1d(hi1[c].unique(), hi2[c].unique()))\n",
    "        vc1 = hi1[c].value_counts().to_dict()\n",
    "        total_junk = 0\n",
    "        for j in junk:\n",
    "            total_junk += vc1[j]\n",
    "        print(total_junk)\n",
    "        print(\"Missing\")\n",
    "        missing = np.setdiff1d(hi2[c].unique(), hi1[c].unique())\n",
    "        print(np.setdiff1d(hi2[c].unique(), hi1[c].unique()))\n",
    "        vc2 = hi2[c].value_counts().to_dict()\n",
    "        total_missing = 0\n",
    "        for m in missing:\n",
    "            total_missing += vc2[m]\n",
    "        print(total_missing)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "\n",
    "print_junk_missing(nominal, data=final_data, prediction_data=final_pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348e4e1-e475-469f-bc95-86e99fb53cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.corrwith(final_data.label, method=\"kendall\").sort_values().iloc[:-1].plot(\n",
    "    kind=\"bar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11df823-cc9b-4c2a-933e-07dfe0216514",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_df = final_data.select_dtypes(include=\"category\")\n",
    "count = 0\n",
    "for c in nominal:\n",
    "\n",
    "    _unique = final_cat_df[c].unique()\n",
    "    count += len(_unique)\n",
    "    print(len(_unique))\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a1d80-63eb-4591-9348-d34dcb3ffdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_nominal_final = pd.get_dummies(final_data, columns=nominal, sparse=False)\n",
    "ohe_train_labels = pd.get_dummies(data.label)\n",
    "\n",
    "# ohe_nominal_final.corrwith(data.label, method='kendall').sort_values().iloc[:-1].plot(kind='bar')\n",
    "ohe_nominal_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e466398-1797-47ff-bde4-e9fed4d68be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_nominal_final.corrwith(ohe_train_labels[0], method=\"kendall\").sort_values().iloc[\n",
    "    :-1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f3193-dc60-4e52-956d-45468f03ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_nominal_final.corrwith(ohe_train_labels[1], method=\"kendall\").sort_values().iloc[\n",
    "    :-1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7ebb8-4a37-40b2-8dfb-163688ea7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_nominal_final.corrwith(ohe_train_labels[2], method=\"kendall\").sort_values().iloc[\n",
    "    :-1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2f042feb-85ca-4182-8a8b-df6cb06d605c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e {color: black;background-color: white;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e pre{padding: 0;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-toggleable {background-color: white;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-estimator:hover {background-color: #d4ebff;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-item {z-index: 1;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-parallel-item:only-child::after {width: 0;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-27aadc72-618a-4665-a5e6-0d6dcca9c67e\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(generations=10, log_file=&#x27;../data/tpot_08_02_48_2022.log&#x27;,\n",
       "               n_jobs=-1,\n",
       "               periodic_checkpoint_folder=&#x27;../data/tpot/periodic_checkpoints/&#x27;,\n",
       "               population_size=10, random_state=42, scoring=&#x27;f1_macro&#x27;,\n",
       "               use_dask=True, warm_start=True)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a59aeff3-ae5c-4e1d-8fc7-861a11906681\" type=\"checkbox\" checked><label for=\"a59aeff3-ae5c-4e1d-8fc7-861a11906681\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(generations=10, log_file=&#x27;../data/tpot_08_02_48_2022.log&#x27;,\n",
       "               n_jobs=-1,\n",
       "               periodic_checkpoint_folder=&#x27;../data/tpot/periodic_checkpoints/&#x27;,\n",
       "               population_size=10, random_state=42, scoring=&#x27;f1_macro&#x27;,\n",
       "               use_dask=True, warm_start=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(generations=10, log_file='../data/tpot_08_02_48_2022.log',\n",
       "               n_jobs=-1,\n",
       "               periodic_checkpoint_folder='../data/tpot/periodic_checkpoints/',\n",
       "               population_size=10, random_state=42, scoring='f1_macro',\n",
       "               use_dask=True, warm_start=True)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "run_time = time.asctime().replace(\" \", \"_\")[11:].replace(\":\", \"_\")\n",
    "tclf = TPOTClassifier(\n",
    "    generations=10,\n",
    "    population_size=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_macro\",\n",
    "    random_state=42,\n",
    "    warm_start=True,\n",
    "    periodic_checkpoint_folder=\"../data/tpot/periodic_checkpoints/\",\n",
    "    use_dask=True,\n",
    "    verbosity=0,\n",
    "    log_file=f\"../data/tpot_{run_time}.log\",\n",
    ")\n",
    "# tclf.fit()\n",
    "tclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "923ac0dd-b620-49c2-aa4e-571ff8b84990",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Nystroem(n_components=900)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Nystroem</label><div class=\"sk-toggleable__content\"><pre>Nystroem(n_components=900)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Nystroem(n_components=900)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = gen_train_test(final_data, 1.0)\n",
    "\n",
    "\n",
    "X_train = final_data.loc[train_idx, nominal]\n",
    "y_train = data.label.loc[train_idx]\n",
    "# y_train = pd.get_dummies(data.label)\n",
    "from dask.distributed import Client\n",
    "\n",
    "# with parallel_backend('dask'):\n",
    "#     warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#     tclf.fit(X_train,y_train)\n",
    "# client = Client()\n",
    "# from sklearnex import unpatch_sklearn\n",
    "# unpatch_sklearn()\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "nys = Nystroem(\n",
    "    n_components=900,\n",
    ")\n",
    "nys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "340a2b34-4d72-42b3-9e0d-b41e73b9714c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([7.00602984, 6.08168387, 9.93439841]),\n",
       " 'score_time': array([2.10018253, 2.33061242, 2.09937835]),\n",
       " 'estimator': [Pipeline(memory=Memory(location=../data/tpot/joblib),\n",
       "           steps=[('OHE',\n",
       "                   OneHotEncoder(handle_unknown='infrequent_if_exist',\n",
       "                                 min_frequency=1e-05, sparse=False)),\n",
       "                  ('FS', SelectKBest(k=350)),\n",
       "                  ('ML',\n",
       "                   GaussianProcessClassifier(max_iter_predict=10000, n_jobs=-1,\n",
       "                                             n_restarts_optimizer=10))]),\n",
       "  Pipeline(memory=Memory(location=../data/tpot/joblib),\n",
       "           steps=[('OHE',\n",
       "                   OneHotEncoder(handle_unknown='infrequent_if_exist',\n",
       "                                 min_frequency=1e-05, sparse=False)),\n",
       "                  ('FS', SelectKBest(k=350)),\n",
       "                  ('ML',\n",
       "                   GaussianProcessClassifier(max_iter_predict=10000, n_jobs=-1,\n",
       "                                             n_restarts_optimizer=10))]),\n",
       "  Pipeline(memory=Memory(location=../data/tpot/joblib),\n",
       "           steps=[('OHE',\n",
       "                   OneHotEncoder(handle_unknown='infrequent_if_exist',\n",
       "                                 min_frequency=1e-05, sparse=False)),\n",
       "                  ('FS', SelectKBest(k=350)),\n",
       "                  ('ML',\n",
       "                   GaussianProcessClassifier(max_iter_predict=10000, n_jobs=-1,\n",
       "                                             n_restarts_optimizer=10))])],\n",
       " 'test_score': array([0.62559796, 0.57727457, 0.60423042]),\n",
       " 'train_score': array([0.94281443, 0.92323658, 0.94859325])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtc = RandomForestClassifier(random_state=42,n_jobs=-1, criterion='entropy', max_features=None)\n",
    "model = GaussianProcessClassifier(\n",
    "    n_jobs=-1, n_restarts_optimizer=10, max_iter_predict=10000\n",
    ")\n",
    "# model = LogisticRegression(max_iter=10000,n_jobs=-1)\n",
    "# dtc = LogisticRegression(max_iter=10000,n_jobs=-1,random_state=42)\n",
    "# fs = SelectFpr(alpha=1)\n",
    "# fs = SelectFwe()\n",
    "# fs = SelectPercentile(percentile=30)\n",
    "# fs = SelectFdr(alpha=0.5)\n",
    "with parallel_backend(\"dask\"):\n",
    "    cv_results = cross_validate(\n",
    "        ovr,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        scoring=\"f1_macro\",\n",
    "        return_train_score=True,\n",
    "        return_estimator=True,\n",
    "    )\n",
    "# client.close()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "234458cf-b88c-437b-9dca-6355d2ea4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82166d1a-22b0-4440-aeb9-29b4fd4d27d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b35a04b-a250-4f8f-9ddd-1bf07c1d2441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9497db-df0b-4111-8157-6b0e583977c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SVC', SVC()),\n",
       " ('NuSVC', NuSVC()),\n",
       " ('CategoricalNB', CategoricalNB()),\n",
       " ('MultinomialNB', MultinomialNB()),\n",
       " ('ComplementNB', ComplementNB()),\n",
       " ('GaussianNB', GaussianNB()),\n",
       " ('AdaBoostClassifier', AdaBoostClassifier()),\n",
       " ('PassiveAggressiveClassifier', PassiveAggressiveClassifier()),\n",
       " ('SGDClassifier', SGDClassifier()),\n",
       " ('KNeighborsClassifier', KNeighborsClassifier()),\n",
       " ('RadiusNeighborsClassifier', RadiusNeighborsClassifier()),\n",
       " ('ExtraTreesClassifier', ExtraTreesClassifier()),\n",
       " ('RandomForestClassifier', RandomForestClassifier()),\n",
       " ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
       " ('HistGradientBoostingClassifier', HistGradientBoostingClassifier()),\n",
       " ('GradientBoostingClassifier', GradientBoostingClassifier())]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (autoskl)",
   "language": "python",
   "name": "autoskl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
