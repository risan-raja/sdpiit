{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2aba7b-b4e8-45f3-9d62-3d3823e0b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    Binarizer,\n",
    "    StandardScaler,\n",
    "    LabelBinarizer,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "# from xgboost import XGBRFClassifier, XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# sns.set()\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.plotting.backend = \"matplotlib\"\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    MinMaxScaler,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "import warnings\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    # StratifiedGroupKFold,\n",
    "\n",
    "    StratifiedKFold,\n",
    ")\n",
    "import sigopt\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, MultinomialNB, ComplementNB, GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "nb_est = [CategoricalNB(), MultinomialNB(), ComplementNB(), GaussianNB()]\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# from xgboost import XGBClassifier\n",
    "from joblib import parallel_backend\n",
    "# from autosklearn.automl import AutoMLClassifier\n",
    "import sklearn.metrics\n",
    "dtype_info = {\n",
    "    \"v_1\": \"Binary\",\n",
    "    \"v_26\": \"Binary\",\n",
    "    \"v_11\": \"Binary\",\n",
    "    \"v_14\": \"Binary\",\n",
    "    \"v_30\": \"Binary\",\n",
    "    \"v_28\": \"Binary\",\n",
    "    \"v_9\": \"Binary\",\n",
    "    \"v_27\": \"Binary\",\n",
    "    \"v_32\": \"Nominal\",\n",
    "    \"v_4\": \"Nominal\",\n",
    "    \"v_3\": \"Nominal\",\n",
    "    \"v_20\": \"Nominal\",\n",
    "    \"v_21\": \"Nominal\",\n",
    "    \"v_18\": \"Nominal\",\n",
    "    \"v_25\": \"Nominal\",\n",
    "    \"v_12\": \"Nominal\",\n",
    "    \"v_31\": \"Ordinal\",\n",
    "    \"v_15\": \"Ordinal\",\n",
    "    \"v_19\": \"Ordinal\",\n",
    "    \"v_13\": \"Ordinal\",\n",
    "    \"v_33\": \"Ordinal\",\n",
    "    \"v_17\": \"Ordinal\",\n",
    "    \"v_29\": \"Ordinal\",\n",
    "    \"v_23\": \"Ordinal\",\n",
    "    \"v_6\": \"Ordinal\",\n",
    "    \"v_24\": \"Ordinal\",\n",
    "    \"v_10\": \"Ordinal\",\n",
    "    \"v_5\": \"Ordinal\",\n",
    "    \"v_22\": \"Ordinal\",\n",
    "    \"v_0\": \"Ordinal\",\n",
    "    \"v_16\": \"Ratio\",\n",
    "    \"v_2\": \"Ratio\",\n",
    "    \"v_8\": \"Ratio\",\n",
    "    \"v_7\": \"Ratio\",\n",
    "    \"v_39\": \"Ratio\",\n",
    "    \"v_37\": \"Ratio\",\n",
    "    \"v_38\": \"Ratio\",\n",
    "    \"v_34\": \"Ratio\",\n",
    "    \"v_40\": \"Ratio\",\n",
    "    \"v_36\": \"Ratio\",\n",
    "    \"v_35\": \"Ratio\",\n",
    "}\n",
    "data = pd.read_csv('../data/train.csv',index_col=0,)\n",
    "ordinal = [i for i in dtype_info if dtype_info[i] == \"Ordinal\"]\n",
    "nominal = [i for i in dtype_info if dtype_info[i] == \"Nominal\"]\n",
    "binary = [i for i in dtype_info if dtype_info[i] == \"Binary\"]\n",
    "ratio = [i for i in dtype_info if dtype_info[i] == \"Ratio\"]\n",
    "def categorise_data(data):\n",
    "    ordinal_data = data.loc[:, ordinal]\n",
    "    nominal_data = data.loc[:, nominal]\n",
    "    binary_data = data.loc[:, binary]\n",
    "    ratio_data = data.loc[:, ratio]\n",
    "    return ordinal_data, nominal_data, binary_data, ratio_data\n",
    "ordinal_data, nominal_data, binary_data, ratio_data = categorise_data(data)\n",
    "def gen_train_test(data, p):\n",
    "    Y = data.label\n",
    "    X_2= Y_2 = Y[Y==2].index\n",
    "    X_0= Y_0 = Y[Y==0].index\n",
    "    X_1= Y_1 = Y[Y==1].index\n",
    "    train_size = int(p*Y_2.shape[0])\n",
    "    test_size = int((1-p)*Y_2.shape[0])\n",
    "    \n",
    "    train_idx_2 = np.random.choice(Y_2,(train_size,))\n",
    "    train_idx_1 = np.random.choice(Y_1,(train_size,))\n",
    "    train_idx_0 = np.random.choice(Y_0,(train_size,))\n",
    "    train_idx = np.r_[train_idx_0, train_idx_1,train_idx_2]\n",
    "    # train_idx.shape\n",
    "\n",
    "    test_idx_2 = np.random.choice(np.setdiff1d(Y_2, train_idx_2),(test_size,))\n",
    "    test_idx_1 = np.random.choice(np.setdiff1d(Y_1, train_idx_1),(test_size,))\n",
    "    test_idx_0 = np.random.choice(np.setdiff1d(Y_0, train_idx_0),(test_size,))\n",
    "    test_idx = np.r_[test_idx_0, test_idx_1,test_idx_2]\n",
    "    # test_idx.shape\n",
    "    return train_idx, test_idx\n",
    "data__ = pd.read_parquet('../data/data_with_ridit.hdfs', engine='fastparquet')\n",
    "import os\n",
    "os.environ[\"SIGOPT_PROJECT\"] = 'notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c21c6-69de-4839-96d6-906d3fc70eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sigopt\n",
    "%sigopt config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b195e-218a-4d67-94af-d5436d03311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc__params = {'ccp_alpha': 0.0,\n",
    " 'class_weight': None,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': None,\n",
    " 'max_leaf_nodes': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'random_state': None,\n",
    " 'splitter': 'best'}\n",
    "\n",
    "# dtc.get_params()\n",
    "def evaluate_best_dtc(n_cv):\n",
    "    global data\n",
    "    dtc__params = {'ccp_alpha': 0.0,\n",
    "                 'class_weight': None,\n",
    "                 'criterion': 'gini',\n",
    "                 'max_depth': None,\n",
    "                 'max_features': None,\n",
    "                 'max_leaf_nodes': None,\n",
    "                 'min_impurity_decrease': 0.0,\n",
    "                 'min_impurity_split': None,\n",
    "                 'min_samples_leaf': np.random.randint(1,5),\n",
    "                 'min_samples_split': 2,\n",
    "                 'min_weight_fraction_leaf': 0.0,\n",
    "                 'random_state': 42,\n",
    "                 'splitter': 'best'}\n",
    "    sigopt.log_dataset(\"Ordinal_Data\")\n",
    "    sigopt.log_model(DecisionTreeClassifier().__class__.__name__)\n",
    "    sigopt.log_metadata(key='Features', value=ordinal)\n",
    "    \n",
    "    train_idx, test_idx = gen_train_test(data, 1.0)\n",
    "    # X_train, y_train = ordinal_data.loc[train_idx, :], pd.get_dummies(data['label'].loc[train_idx])\n",
    "    X_train, y_train = ordinal_data.loc[train_idx, :], data['label'].loc[train_idx]\n",
    "    for k,v in dtc__params.items():\n",
    "        sigopt.params.setdefault(k,v)\n",
    "    # clf = OneVsRestClassifier(model, n_jobs=-1)\n",
    "    with parallel_backend('threading', n_jobs=-1):\n",
    "        model = DecisionTreeClassifier(max_features=14, \n",
    "                                       min_samples_leaf=dtc__params['min_samples_leaf'],\n",
    "                                       min_impurity_decrease=sigopt.params.min_impurity_decrease,\n",
    "                                      random_state=42,\n",
    "                                      ccp_alpha=sigopt.params.ccp_alpha)\n",
    "        cv_results = cross_validate(model, X_train, y_train, scoring='f1_macro', return_train_score=True, n_jobs=-1, cv=n_cv, return_estimator=True)\n",
    "        sigopt.params.min_samples_leaf = model.min_samples_leaf\n",
    "    # sigopt.params.ccp_alpha=0\n",
    "    # print(sigopt.params)\n",
    "    sigopt.log_metric(name='f1_macro', value=cv_results['test_score'].mean())\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c40f3-1d2e-4c4f-8bf6-d9196f02f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%experiment\n",
    "{\n",
    "    'name': 'DTC Optimization',\n",
    "    'metrics': [\n",
    "        {\n",
    "            'name': 'f1_macro',\n",
    "            'strategy': 'optimize',\n",
    "            'objective': 'maximize',\n",
    "        }\n",
    "    ],\n",
    "    'parameters': [\n",
    "        {\n",
    "            'name': 'min_impurity_decrease',\n",
    "            'type': 'double',\n",
    "            'bounds': {'min': 0.0, 'max': 1.0}\n",
    "        }\n",
    "\n",
    "    ],\n",
    "    'type':'offline',\n",
    "    'budget': 10\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c650483-e91f-4159-b8e1-5ca7b53c5eaf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%optimize \n",
    "evaluate_best_dtc(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405a38b-7b89-40fb-b1e0-cabfcc0a9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = nom_dum.loc[train_idx,:], data['label'].loc[train_idx]\n",
    "# X_train, y_train = nominal_data.loc[train_idx,:], data['label'].loc[train_idx]\n",
    "# X_train, y_train = nom_dum.iloc[train_idx,imp_nom], data['label'].loc[train_idx]\n",
    "# cv_results = cross_validate(dtc, X_train, y_train, scoring='f1_macro', return_train_score=True, n_jobs=-1, cv=10, return_estimator=True, )\n",
    "# cv_results\n",
    "train_idx, test_idx = gen_train_test(data, 0.75)\n",
    "X_train, y_train = nominal_data.loc[train_idx,:].astype('category'), data['label'].loc[train_idx]\n",
    "X_test, y_test = nominal_data.loc[test_idx,:].astype('category'), data[\"label\"].loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d561de-5b2f-47a8-9560-9c92eb65d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "def qt_trial():\n",
    "    qt = QuantileTransformer(n_quantiles=200,output_distribution='normal', random_state=42)\n",
    "    train_idx, test_idx = gen_train_test(data, 1.0)\n",
    "    X_train, y_train = ordinal_data.loc[train_idx, [ 'v_10', 'v_17', 'v_5', 'v_29', 'v_19', 'v_22', 'v_6']], data['label'].loc[train_idx]\n",
    "    for c in X_train:\n",
    "        med = X_train[c].median()\n",
    "        X_train[c] = ((X_train[c])/med)\n",
    "    with parallel_backend('threading', n_jobs=-1):\n",
    "        model = DecisionTreeClassifier(criterion='entropy',\n",
    "                                    # max_features='sqrt',\n",
    "\n",
    "                                    # learning_rate=0.\n",
    "                                       # n_jobs=-1,\n",
    "                                       # min_samples_leaf=1,\n",
    "                                      random_state=42,)\n",
    "        model_wf = make_pipeline(qt, model)\n",
    "        cv_results = cross_validate(model_wf, X_train, y_train, scoring='f1_macro', return_train_score=True, n_jobs=-1, cv=3, return_estimator=True, )\n",
    "    cv_results['test_score'].mean(),cv_results['train_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb61bc8-db87-4ec5-b93e-4c27aa35dc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (autoskl)",
   "language": "python",
   "name": "autoskl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
